@article{Trousdale2012,
author = {Trousdale, James and Hu, Yu and Shea-Brown, Eric and Josi\'{c}, Kre\v{s}imir},
doi = {10.1371/journal.pcbi.1002408},
editor = {Sporns, Olaf},
file = {:Users/alex/Documents/Mendeley Desktop/Trousdale et al. - 2012 - Impact of Network Structure and Cellular Response on Spike Time Correlations.pdf:pdf},
issn = {1553-7358},
journal = {PLoS Computational Biology},
month = mar,
number = {3},
pages = {e1002408},
title = {{Impact of Network Structure and Cellular Response on Spike Time Correlations}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1002408},
volume = {8},
year = {2012}
}
@article{Berkes2011,
abstract = {The brain maintains internal models of its environment to interpret sensory inputs and to prepare actions. Although behavioral studies have demonstrated that these internal models are optimally adapted to the statistics of the environment, the neural underpinning of this adaptation is unknown. Using a Bayesian model of sensory cortical processing, we related stimulus-evoked and spontaneous neural activities to inferences and prior expectations in an internal model and predicted that they should match if the model is statistically optimal. To test this prediction, we analyzed visual cortical activity of awake ferrets during development. Similarity between spontaneous and evoked activities increased with age and was specific to responses evoked by natural scenes. This demonstrates the progressive adaptation of internal models to the statistics of natural stimuli at the neural level.},
author = {Berkes, Pietro and Orb\'{a}n, Gergo and Lengyel, M\'{a}t\'{e} and Fiser, J\'{o}zsef},
doi = {10.1126/science.1195870},
file = {:Users/alex/Documents/Mendeley Desktop/Berkes et al. - 2011 - Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment.pdf:pdf},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Action Potentials,Adaptation, Physiological,Aging,Animals,Bayes Theorem,Darkness,Electrodes, Implanted,Evoked Potentials, Visual,Ferrets,Models, Neurological,Neurons,Neurons: physiology,Photic Stimulation,Visual Cortex,Visual Cortex: growth \& development,Visual Cortex: physiology,Visual Perception},
month = jan,
number = {6013},
pages = {83--7},
pmid = {21212356},
title = {{Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3065813\&tool=pmcentrez\&rendertype=abstract},
volume = {331},
year = {2011}
}
@article{Doi2006,
author = {Doi, Eizaburo and Balcan, D.C. and Lewicki, M.S.},
file = {:Users/alex/Documents/Mendeley Desktop/Doi, Balcan, Lewicki - 2006 - A theoretical analysis of robust coding over noisy overcomplete channels.pdf:pdf},
journal = {Advances in neural information processing systems},
pages = {307},
publisher = {MIT; 1998},
title = {{A theoretical analysis of robust coding over noisy overcomplete channels}},
url = {http://www.cns.nyu.edu/csh/csh06/PDFs/Doi-Balcan-Lewicki-06-ANIPS.pdf},
volume = {18},
year = {2006}
}
@article{Berens2011,
abstract = {Cortical circuits perform the computations underlying rapid perceptual decisions within a few dozen milliseconds with each neuron emitting only a few spikes. Under these conditions, the theoretical analysis of neural population codes is challenging, as the most commonly used theoretical tool--Fisher information--can lead to erroneous conclusions about the optimality of different coding schemes. Here we revisit the effect of tuning function width and correlation structure on neural population codes based on ideal observer analysis in both a discrimination and a reconstruction task. We show that the optimal tuning function width and the optimal correlation structure in both paradigms strongly depend on the available decoding time in a very similar way. In contrast, population codes optimized for Fisher information do not depend on decoding time and are severely suboptimal when only few spikes are available. In addition, we use the neurometric functions of the ideal observer in the classification task to investigate the differential coding properties of these Fisher-optimal codes for fine and coarse discrimination. We find that the discrimination error for these codes does not decrease to zero with increasing population size, even in simple coarse discrimination tasks. Our results suggest that quite different population codes may be optimal for rapid decoding in cortical computations than those inferred from the optimization of Fisher information.},
author = {Berens, Philipp and Ecker, Alexander S and Gerwinn, Sebastian and Tolias, Andreas S and Bethge, Matthias},
doi = {10.1073/pnas.1015904108},
file = {:Users/alex/Documents/Mendeley Desktop/Berens et al. - 2011 - Reassessing optimal neural population codes with neurometric functions.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Action Potentials,Action Potentials: physiology,Models, Neurological,Neurons,Neurons: physiology,Physical Stimulation},
month = mar,
number = {11},
pages = {4423--8},
pmid = {21368193},
title = {{Reassessing optimal neural population codes with neurometric functions.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3060259\&tool=pmcentrez\&rendertype=abstract},
volume = {108},
year = {2011}
}
@misc{bbcwildlife,
title = {{BBC Nature Wildlife}},
url = {http://www.bbc.co.uk/nature/wildlife}
}
@article{Ganguli2012,
author = {Ganguli, Surya and Sompolinsky, Haim},
doi = {10.1146/annurev-neuro-062111},
file = {:Users/alex/Documents/Mendeley Desktop/Ganguli, Sompolinsky - 2012 - Compressed Sensing , Sparsity , and Dimensionality in Neuronal Information Processing and Data Analysis.pdf:pdf},
keywords = {communication,connectomics,generalization,imaging,learning,memory,random projections},
title = {{Compressed Sensing , Sparsity , and Dimensionality in Neuronal Information Processing and Data Analysis}},
year = {2012}
}
@article{Brunel1997,
author = {Brunel, Nicolas and Nadal, Jean-Pierre},
file = {:Users/alex/Documents/Mendeley Desktop/Brunel, Nadal - 1997 - Optimal tuning curves for neurons spiking as a Poisson process.pdf:pdf},
journal = {in Proceedings of the ESANN Conference (D facto \ldots},
title = {{Optimal tuning curves for neurons spiking as a Poisson process}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.50.4239\&rep=rep1\&type=pdf},
year = {1997}
}
@inproceedings{Susemihl2012,
address = {M\"{u}nchen},
author = {Susemihl, Alex and Meir, Ron and Opper, Manfred},
booktitle = {Bernstein Conference 2012},
keywords = {optimal filtering,optimal tuning width,particle filtering},
publisher = {Frontiers},
title = {{Online Stimulus Reconstruction from Noisy Spike Trains}},
url = {http://www.frontiersin.org/10.3389/conf.fncom.2012.55.00137/event\_abstract},
year = {2012}
}
@article{Yu2009,
abstract = {We consider the problem of extracting smooth, low-dimensional neural trajectories that summarize the activity recorded simultaneously from many neurons on individual experimental trials. Beyond the benefit of visualizing the high-dimensional, noisy spiking activity in a compact form, such trajectories can offer insight into the dynamics of the neural circuitry underlying the recorded activity. Current methods for extracting neural trajectories involve a two-stage process: the spike trains are first smoothed over time, then a static dimensionality-reduction technique is applied. We first describe extensions of the two-stage methods that allow the degree of smoothing to be chosen in a principled way and that account for spiking variability, which may vary both across neurons and across time. We then present a novel method for extracting neural trajectories-Gaussian-process factor analysis (GPFA)-which unifies the smoothing and dimensionality-reduction operations in a common probabilistic framework. We applied these methods to the activity of 61 neurons recorded simultaneously in macaque premotor and motor cortices during reach planning and execution. By adopting a goodness-of-fit metric that measures how well the activity of each neuron can be predicted by all other recorded neurons, we found that the proposed extensions improved the predictive ability of the two-stage methods. The predictive ability was further improved by going to GPFA. From the extracted trajectories, we directly observed a convergence in neural state during motor planning, an effect that was shown indirectly by previous studies. We then show how such methods can be a powerful tool for relating the spiking activity across a neural population to the subject's behavior on a single-trial basis. Finally, to assess how well the proposed methods characterize neural population activity when the underlying time course is known, we performed simulations that revealed that GPFA performed tens of percent better than the best two-stage method.},
author = {Yu, Byron M and Cunningham, John P and Santhanam, Gopal and Ryu, Stephen I and Shenoy, Krishna V and Sahani, Maneesh},
doi = {10.1152/jn.90941.2008},
file = {:Users/alex/Documents/Mendeley Desktop/Yu et al. - 2009 - Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity.pdf:pdf},
issn = {0022-3077},
journal = {Journal of neurophysiology},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Computer-Assisted,Models,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neurological,Neurons,Neurons: physiology,Nonlinear Dynamics,Normal Distribution,Principal Component Analysis,Reaction Time,Reaction Time: physiology,Signal Processing,Time Factors},
month = jul,
number = {1},
pages = {614--35},
pmid = {19357332},
title = {{Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2712272\&tool=pmcentrez\&rendertype=abstract},
volume = {102},
year = {2009}
}
@article{Somel2011,
author = {Somel, Mehmet and Liu, Xiling and Tang, Lin and Yan, Zheng and Hu, Haiyang and Guo, Song and Jiang, Xi and Zhang, Xiaoyu and Xu, Guohua and Xie, Gangcai and Li, Na and Hu, Yuhui and Chen, Wei and P\"{a}\"{a}bo, Svante and Khaitovich, Philipp},
doi = {10.1371/journal.pbio.1001214},
editor = {Penny, David},
file = {:Users/alex/Documents/Mendeley Desktop/Somel et al. - 2011 - MicroRNA-Driven Developmental Remodeling in the Brain Distinguishes Humans from Other Primates.pdf:pdf},
issn = {1545-7885},
journal = {PLoS Biology},
month = dec,
number = {12},
pages = {e1001214},
title = {{MicroRNA-Driven Developmental Remodeling in the Brain Distinguishes Humans from Other Primates}},
url = {http://dx.plos.org/10.1371/journal.pbio.1001214},
year = {2011}
}
@article{Wang2009,
author = {Wang, Zhou and Li, Qiang},
doi = {10.1117/12.810176},
file = {:Users/alex/Documents/Mendeley Desktop/Wang, Li - 2009 - Statistics of natural image sequences temporal motion smoothness by local phase correlations.pdf:pdf},
journal = {Proceedings of SPIE},
keywords = {complex wavelet,image quality assessment,image sequence statistics,local phase correlation,natural image statistics,reduced reference video quality assessment,temporal motion smoothness,transform},
pages = {72400W--72400W--12},
publisher = {Spie},
title = {{Statistics of natural image sequences: temporal motion smoothness by local phase correlations}},
url = {http://link.aip.org/link/PSISDG/v7240/i1/p72400W/s1\&Agg=doi},
volume = {7240},
year = {2009}
}
@article{Osindero2006,
abstract = {We present an energy-based model that uses a product of generalized Student-t distributions to capture the statistical structure in data sets. This model is inspired by and particularly applicable to "natural" data sets such as images. We begin by providing the mathematical framework, where we discuss complete and overcomplete models and provide algorithms for training these models from data. Using patches of natural scenes, we demonstrate that our approach represents a viable alternative to independent component analysis as an interpretive model of biological visual systems. Although the two approaches are similar in flavor, there are also important differences, particularly when the representations are overcomplete. By constraining the interactions within our model, we are also able to study the topographic organization of Gabor-like receptive fields that our model learns. Finally, we discuss the relation of our new approach to previous work-in particular, gaussian scale mixture models and variants of independent components analysis.},
author = {Osindero, Simon and Welling, Max and Hinton, Geoffrey E},
institution = {Department of Computer Science, University of Toronto, Toronto, Ontario, M5S 3G4, Canada. osindero@cs.toronto.edu},
journal = {Neural Computation},
number = {2},
pages = {381--414},
pmid = {16378519},
publisher = {MIT Press},
title = {{Topographic product models applied to natural scene statistics.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16378519},
volume = {18},
year = {2006}
}
@article{Kording2004,
abstract = {Sensory areas should be adapted to the properties of their natural stimuli. What are the underlying rules that match the properties of complex cells in primary visual cortex to their natural stimuli? To address this issue, we sampled movies from a camera carried by a freely moving cat, capturing the dynamics of image motion as the animal explores an outdoor environment. We use these movie sequences as input to simulated neurons. Following the intuition that many meaningful high-level variables, e.g., identities of visible objects, do not change rapidly in natural visual stimuli, we adapt the neurons to exhibit firing rates that are stable over time. We find that simulated neurons, which have optimally stable activity, display many properties that are observed for cortical complex cells. Their response is invariant with respect to stimulus translation and reversal of contrast polarity. Furthermore, spatial frequency selectivity and the aspect ratio of the receptive field quantitatively match the experimentally observed characteristics of complex cells. Hence, the population of complex cells in the primary visual cortex can be described as forming an optimally stable representation of natural stimuli.},
author = {K\"{o}rding, Konrad P and Kayser, Christoph and Einh\"{a}user, Wolfgang and K\"{o}nig, Peter},
doi = {10.1152/jn.00149.2003},
file = {:Users/alex/Documents/Mendeley Desktop/K\"{o}rding et al. - 2004 - How are complex cell properties adapted to the statistics of natural stimuli.pdf:pdf},
issn = {0022-3077},
journal = {Journal of neurophysiology},
keywords = {Animals,Cats,Computer Simulation,Models, Neurological,Neural Networks (Computer),Neurons,Neurons: physiology,Orientation,Photic Stimulation,Space Perception,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,Visual Fields,Visual Fields: physiology,Visual Pathways,Visual Pathways: anatomy \& histology,Visual Pathways: physiology},
month = jan,
number = {1},
pages = {206--12},
pmid = {12904330},
title = {{How are complex cell properties adapted to the statistics of natural stimuli?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12904330},
volume = {91},
year = {2004}
}
@inproceedings{cadieu2008,
author = {Cadieu, Charles F and Olshausen, Bruno A},
booktitle = {Advances in Neural Information Processing Systems 21},
file = {:Users/alex/Documents/Mendeley Desktop/Cadieu, Olshausen - 2008 - Learning Transformational Invariants from Natural Movies.pdf:pdf},
pages = {1--8},
title = {{Learning Transformational Invariants from Natural Movies}},
year = {2008}
}
@article{Beck2012,
abstract = {Behavior varies from trial to trial even when the stimulus is maintained as constant as possible. In many models, this variability is attributed to noise in the brain. Here, we propose that there is another major source of variability: suboptimal inference. Importantly, we argue that in most tasks of interest, and particularly complex ones, suboptimal inference is likely to be the dominant component of behavioral variability. This perspective explains a variety of intriguing observations, including why variability appears to be larger on the sensory than on the motor side, and why our sensors are sometimes surprisingly unreliable.},
author = {Beck, Jeffrey M. M and Ma, Wei Ji Ji and Pitkow, Xaq and Latham, Peter E. E and Pouget, Alexandre},
doi = {10.1016/j.neuron.2012.03.016},
file = {:Users/alex/Documents/Mendeley Desktop/Beck et al. - 2012 - Not noisy, just wrong the role of suboptimal inference in behavioral variability.pdf:pdf},
issn = {08966273},
journal = {Neuron},
keywords = {Animals,Behavior,Behavioral Research,Brain,Brain: cytology,Brain: physiology,Field Dependence-Independence,Humans,Models,Neurological,Neurons,Neurons: physiology,Perceptual Masking,Perceptual Masking: physiology,Psychological,Reproducibility of Results,Sensation,Sensation: physiology,Uncertainty},
month = apr,
number = {1},
pages = {30--39},
pmid = {22500627},
publisher = {Elsevier Inc.},
title = {{Not noisy, just wrong: the role of suboptimal inference in behavioral variability.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22500627 http://linkinghub.elsevier.com/retrieve/pii/S0896627312002802},
volume = {74},
year = {2012}
}
@article{Macke2011,
abstract = {A striking feature of cortical organization is that the encoding of many stimulus features, for example orientation or direction selectivity, is arranged into topographic maps. Functional imaging methods such as optical imaging of intrinsic signals, voltage sensitive dye imaging or functional magnetic resonance imaging are important tools for studying the structure of cortical maps. As functional imaging measurements are usually noisy, statistical processing of the data is necessary to extract maps from the imaging data. We here present a probabilistic model of functional imaging data based on Gaussian processes. In comparison to conventional approaches, our model yields superior estimates of cortical maps from smaller amounts of data. In addition, we obtain quantitative uncertainty estimates, i.e. error bars on properties of the estimated map. We use our probabilistic model to study the coding properties of the map and the role of noise-correlations by decoding the stimulus from single trials of an imaging experiment.},
author = {Macke, Jakob H and Gerwinn, Sebastian and White, Leonard E and Kaschube, Matthias and Bethge, Matthias},
institution = {Gatsby Computational Neuroscience Unit, University College London, Alexandra House, 17 Queen Square, London WC1N 3AR, UK; MPI for Biological Cybernetics, Computational Vision and Neuroscience Group, Spemannstra\ss e 41, 72076 T\"{u}bingen, Germany; Werner Reicha},
journal = {NeuroImage},
number = {2},
pages = {570--581},
pmid = {20472075},
publisher = {Elsevier Inc.},
title = {{Gaussian process methods for estimating cortical maps.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20472075},
volume = {56},
year = {2011}
}
@article{Bla2011,
author = {Bla, Florian},
doi = {10.1371/Citation},
file = {:Users/alex/Documents/Mendeley Desktop/Bla - 2011 - An Efficient Coding Hypothesis Links Sparsity and Selectivity of Neural Responses Strong.pdf:pdf},
number = {10},
title = {{An Efficient Coding Hypothesis Links Sparsity and Selectivity of Neural Responses Strong}},
volume = {6},
year = {2011}
}
@article{Ergun2007,
abstract = {The stochastic state point process filter (SSPPF) and steepest descent point process filter (SDPPF) are adaptive filter algorithms for state estimation from point process observations that have been used to track neural receptive field plasticity and to decode the representations of biological signals in ensemble neural spiking activity. The SSPPF and SDPPF are constructed using, respectively, Gaussian and steepest descent approximations to the standard Bayes and Chapman-Kolmogorov (BCK) system of filter equations. To extend these approaches for constructing point process adaptive filters, we develop sequential Monte Carlo (SMC) approximations to the BCK equations in which the SSPPF and SDPPF serve as the proposal densities. We term the two new SMC point process filters SMC-PPFs and SMC-PPFD, respectively. We illustrate the new filter algorithms by decoding the wind stimulus magnitude from simulated neural spiking activity in the cricket cercal system. The SMC-PPFs and SMC-PPFD provide more accurate state estimates at low number of particles than a conventional bootstrap SMC filter algorithm in which the state transition probability density is the proposal density. We also use the SMC-PPFs algorithm to track the temporal evolution of a spatial receptive field of a rat hippocampal neuron recorded while the animal foraged in an open environment. Our results suggest an approach for constructing point process adaptive filters using SMC methods.},
author = {Ergun, A and Barbieri, R and Eden, U T and Wilson, M A and Brown, E N},
doi = {10.1109/TBME.2006.888821},
file = {:Users/alex/Documents/Mendeley Desktop/Ergun et al. - 2007 - Construction of point process adaptive filter algorithms for neural systems using sequential Monte Carlo methods.pdf:pdf},
institution = {Neuroscience Statistics Research Laboratory, Department of Anesthesia and Critical Care, Massachusetts General Hospital, Boston, MA 02114-2698, USA. ayla@neurostat.mgh.harvard.edu},
issn = {00189294},
journal = {IEEE Transactions on Biomedical Engineering},
keywords = {action potentials,action potentials physiology,algorithms,animals,computer assisted,hippocampus,hippocampus physiology,models,monte carlo method,nerve net,nerve net physiology,neurological,neuronal plasticity,neuronal plasticity physiology,rats,signal processing,statistical,stochastic processes},
number = {3},
pages = {419--428},
pmid = {17355053},
publisher = {IEEE},
title = {{Construction of point process adaptive filter algorithms for neural systems using sequential Monte Carlo methods.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17355053},
volume = {54},
year = {2007}
}
@article{Olshausen2004,
author = {Olshausen, Bruno A and Field, David J},
file = {:Users/alex/Documents/Mendeley Desktop/Olshausen, Field - 2004 - What is the other 85 \% of V1 doing.pdf:pdf},
pages = {1--29},
title = {{What is the other 85 \% of V1 doing ?}},
year = {2004}
}
@book{Casella,
author = {Casella, George and Fienberg, Stephen and Olkin, Ingram},
file = {:Users/alex/Documents/Mendeley Desktop/Casella, Fienberg, Olkin - Unknown - Springer Texts in Statistics Springer Texts in Statistics.pdf:pdf},
isbn = {9780387715988},
title = {{Springer Texts in Statistics Springer Texts in Statistics}}
}
@article{Taylor2007,
author = {Taylor, GW and Hinton, GE and Roweis, ST},
file = {:Users/alex/Documents/Mendeley Desktop/Taylor, Hinton, Roweis - 2007 - Modeling human motion using binary latent variables.pdf:pdf},
journal = {Advances in neural information \ldots},
title = {{Modeling human motion using binary latent variables}},
url = {http://cognet.mit.edu/library/books/mitpress/0262195682/cache/chap169.pdf},
year = {2007}
}
@book{mackay2003information,
author = {MacKay, D J C},
publisher = {Cambridge university press},
title = {{Information theory, inference and learning algorithms}},
year = {2003}
}
@article{Pfister2010,
abstract = {The trajectory of the somatic membrane potential of a cortical neuron exactly reflects the computations performed on its afferent inputs. However, the spikes of such a neuron are a very low-dimensional and discrete projection of this continually evolving signal. We explored the possibility that the neuron's efferent synapses perform the critical computational step of estimating the membrane potential trajectory from the spikes. We found that short-term changes in synaptic efficacy can be interpreted as implementing an optimal estimator of this trajectory. Short-term depression arose when presynaptic spiking was sufficiently intense as to reduce the uncertainty associated with the estimate; short-term facilitation reflected structural features of the statistics of the presynaptic neuron such as up and down states. Our analysis provides a unifying account of a powerful, but puzzling, form of plasticity.},
author = {Pfister, Jean-Pascal and Dayan, Peter and Lengyel, M\'{a}t\'{e}},
doi = {10.1038/nn.2640},
file = {:Users/alex/Documents/Mendeley Desktop/Pfister, Dayan, Lengyel - 2010 - Synapses with short-term plasticity are optimal estimators of presynaptic membrane potentials.pdf:pdf},
issn = {1546-1726},
journal = {Nature neuroscience},
keywords = {Animals,Biophysics,Computer Simulation,Membrane Potentials,Membrane Potentials: physiology,Models, Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: cytology,Nonlinear Dynamics,Presynaptic Terminals,Presynaptic Terminals: physiology,Stochastic Processes,Synapses,Synapses: physiology},
month = oct,
number = {10},
pages = {1271--5},
pmid = {20852625},
title = {{Synapses with short-term plasticity are optimal estimators of presynaptic membrane potentials.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20852625},
volume = {13},
year = {2010}
}
@article{Dobzhansky1973,
author = {Dobzhansky, Theodosius},
file = {:Users/alex/Documents/Mendeley Desktop/Dobzhansky - 1973 - Nothing in Biology Makes Sense Except in the Light of Evolution.pdf:pdf},
journal = {The American Biology Teacher},
number = {3},
pages = {125--129},
title = {{Nothing in Biology Makes Sense Except in the Light of Evolution}},
volume = {35},
year = {1973}
}
@article{Shapley1997,
abstract = {The retina needs to process visual information under a wide range of conditions, a feat facilitated by gain controls. Recent results have provided new insights into one such gain control, which enables the retina to adapt to wide variations in the level of contrast in the visual scene.},
author = {Shapley, R},
file = {:Users/alex/Documents/Mendeley Desktop/Shapley - 1997 - Retinal physiology adapting to the changing scene.pdf:pdf},
issn = {0960-9822},
journal = {Current biology : CB},
keywords = {Adaptation, Physiological,Animals,Ganglia,Ganglia: cytology,Ganglia: physiology,Retina,Retina: cytology,Retina: physiology},
month = jul,
number = {7},
pages = {R421--3},
pmid = {9210365},
title = {{Retinal physiology: adapting to the changing scene.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9210365},
volume = {7},
year = {1997}
}
@article{Natarajan2008,
abstract = {Naturally occurring sensory stimuli are dynamic. In this letter, we consider how spiking neural populations might transmit information about continuous dynamic stimulus variables. The combination of simple encoders and temporal stimulus correlations leads to a code in which information is not readily available to downstream neurons. Here, we explore a complex encoder that is paired with a simple decoder that allows representation and manipulation of the dynamic information in neural systems. The encoder we present takes the form of a biologically plausible recurrent spiking neural network where the output population recodes its inputs to produce spikes that are independently decodeable. We show that this network can be learned in a supervised manner by a simple local learning rule.},
author = {Natarajan, Rama and Huys, Quentin J M QJM and Dayan, Peter and Zemel, Richard S RS},
file = {:Users/alex/Documents/Mendeley Desktop/Natarajan et al. - 2008 - Encoding and Decoding Spikes for Dynamic Stimuli.pdf:pdf},
institution = {Department of Computer Science, University of Toronto, Toronto, Ontario, Canada. rama@cs.toronto.edu},
journal = {Neural computation},
keywords = {action potentials,action potentials physiology,computer simulation,models,neural networks (computer),neurological,neurons,neurons physiology,nonlinear dynamics},
number = {9},
pages = {1--36},
publisher = {M I T PRESS},
title = {{Encoding and Decoding Spikes for Dynamic Stimuli}},
url = {http://discovery.ucl.ac.uk/173469/ http://www.mitpressjournals.org/doi/abs/10.1162/neco.2008.01-07-436},
volume = {20},
year = {2008}
}
@article{Opper2009,
abstract = {The variational approximation of posterior distributions by multivariate Gaussians has been much less popular in the Machine Learning community compared to the corresponding approximation by factorising distributions. This is for a good reason: the Gaussian approximation is in general plagued by an Ocal(N 2) number of variational parameters to be optimised, N being the number of random variables. In this work, we discuss the relationship between the Laplace and the variational approximation and we show that for models with Gaussian priors and factorising likelihoods, the number of variational parameters is actually Ocal(N). The approach is applied to Gaussian process regression with non-Gaussian likelihoods.},
author = {Opper, Manfred and Archambeau, Cedric},
institution = {Department of Computer Science, Technical University Berlin, D-10587 Berlin, Germany. opperm@cs.tu-berlin.de},
journal = {Neural Computation},
number = {3},
pages = {786--792},
publisher = {MIT Press},
title = {{The Variational Gaussian Approximation Revisited}},
url = {http://eprints.pascal-network.org/archive/00005264/},
volume = {21},
year = {2009}
}
@article{Ahmadian2011,
abstract = {Stimulus reconstruction or decoding methods provide an important tool for understanding how sensory and motor information is represented in neural activity. We discuss Bayesian decoding methods based on an encoding generalized linear model (GLM) that accurately describes how stimuli are transformed into the spike trains of a group of neurons. The form of the GLM likelihood ensures that the posterior distribution over the stimuli that caused an observed set of spike trains is log concave so long as the prior is. This allows the maximum a posteriori (MAP) stimulus estimate to be obtained using efficient optimization algorithms. Unfortunately, the MAP estimate can have a relatively large average error when the posterior is highly nongaussian. Here we compare several Markov chain Monte Carlo (MCMC) algorithms that allow for the calculation of general Bayesian estimators involving posterior expectations (conditional on model parameters). An efficient version of the hybrid Monte Carlo (HMC) algorithm was significantly superior to other MCMC methods for gaussian priors. When the prior distribution has sharp edges and corners, on the other hand, the "hit-and-run" algorithm performed better than other MCMC methods. Using these algorithms, we show that for this latter class of priors, the posterior mean estimate can have a considerably lower average error than MAP, whereas for gaussian priors, the two estimators have roughly equal efficiency. We also address the application of MCMC methods for extracting nonmarginal properties of the posterior distribution. For example, by using MCMC to calculate the mutual information between the stimulus and response, we verify the validity of a computationally efficient Laplace approximation to this quantity for gaussian priors in a wide range of model parameters; this makes direct model-based computation of the mutual information tractable even in the case of large observed neural populations, where methods based on binning the spike train fail. Finally, we consider the effect of uncertainty in the GLM parameters on the posterior estimators.},
author = {Ahmadian, Yashar and Pillow, Jonathan W and Paninski, Liam},
file = {:Users/alex/Documents/Mendeley Desktop/Ahmadian, Pillow, Paninski - 2011 - Efficient Markov chain Monte Carlo methods for decoding neural spike trains.pdf:pdf},
institution = {Department of Statistics and Center for Theoretical Neuroscience, Columbia University, New York, New York 10027, USA. yashar@stat.columbia.edu},
journal = {Neural Computation},
number = {1},
pages = {46--96},
pmid = {20964539},
publisher = {MIT Press 238 Main St., Suite 500, Cambridge, MA 02142-1046, USA email: journals-info@mit.edu},
title = {{Efficient Markov chain Monte Carlo methods for decoding neural spike trains.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20964539},
volume = {23},
year = {2011}
}
@article{Rucci2005,
abstract = {Under natural viewing conditions, small movements of the eye, head and body prevent the maintenance of a steady direction of gaze. It is known that stimuli tend to fade when they are stabilized on the retina for several seconds. However, it is unclear whether the physiological motion of the retinal image serves a visual purpose during the brief periods of natural visual fixation. This study examines the impact of fixational instability on the statistics of the visual input to the retina and on the structure of neural activity in the early visual system. We show that fixational instability introduces a component in the retinal input signals that, in the presence of natural images, lacks spatial correlations. This component strongly influences neural activity in a model of the LGN. It decorrelates cell responses even if the contrast sensitivity functions of simulated cells are not perfectly tuned to counter-balance the power-law spectrum of natural images. A decorrelation of neural activity at the early stages of the visual system has been proposed to be beneficial for discarding statistical redundancies in the input signals. The results of this study suggest that fixational instability might contribute to the establishment of efficient representations of natural stimuli.},
author = {Rucci, Michele and Casile, Antonino},
file = {:Users/alex/Documents/Mendeley Desktop/Rucci, Casile - 2005 - Fixational instability and natural image statistics implications for early visual representations.pdf:pdf},
institution = {Cognitive and Neural Systems Department, Boston University, 677 Beacon Street, Boston, MA 02215, USA. rucci@cns.bu.edu},
journal = {Network},
number = {2-3},
pages = {121--138},
pmid = {16411492},
title = {{Fixational instability and natural image statistics: implications for early visual representations.}},
url = {http://informahealthcare.com/doi/abs/10.1080/09548980500300507},
volume = {16},
year = {2005}
}
@article{Hasenstaub2010a,
abstract = {The brain contains an astonishing diversity of neurons, each expressing only one set of ion channels out of the billions of potential channel combinations. Simple organizing principles are required for us to make sense of this abundance of possibilities and wealth of related data. We suggest that energy minimization subject to functional constraints may be one such unifying principle. We compared the energy needed to produce action potentials singly and in trains for a wide range of channel densities and kinetic parameters and examined which combinations of parameters maximized spiking function while minimizing energetic cost. We confirmed these results for sodium channels using a dynamic current clamp in neocortical fast spiking interneurons. We find further evidence supporting this hypothesis in a wide range of other neurons from several species and conclude that the ion channels in these neurons minimize energy expenditure in their normal range of spiking.},
author = {Hasenstaub, Andrea and Otte, Stephani and Callaway, Edward and Sejnowski, Terrence J},
doi = {10.1073/pnas.0914886107},
file = {:Users/alex/Documents/Mendeley Desktop/Hasenstaub et al. - 2010 - Metabolic cost as a unifying principle governing neuronal biophysics.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Animals,Brain,Brain: cytology,Computer Simulation,Energy Metabolism,Ion Channels,Ion Channels: physiology,Kinetics,Membrane Potentials,Membrane Potentials: physiology,Mice,Mice, Inbred C57BL,Models, Neurological,Neurons,Neurons: metabolism,Neurons: physiology,Patch-Clamp Techniques,Potassium,Potassium Channels,Potassium Channels: physiology,Potassium: metabolism,Sodium,Sodium Channels,Sodium Channels: physiology,Sodium-Potassium-Exchanging ATPase,Sodium-Potassium-Exchanging ATPase: metabolism,Sodium: metabolism},
month = jul,
number = {27},
pages = {12329--34},
pmid = {20616090},
title = {{Metabolic cost as a unifying principle governing neuronal biophysics.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2901447\&tool=pmcentrez\&rendertype=abstract},
volume = {107},
year = {2010}
}
@article{Oram1998a,
abstract = {Information processing in the nervous system involves the activity of large populations of neurons. It is possible, however, to interpret the activity of relatively small numbers of cells in terms of meaningful aspects of the environment. 'Bayesian inference' provides a systematic and effective method of combining information from multiple cells to accomplish this. It is not a model of a neural mechanism (neither are alternative methods, such as the population vector approach) but a tool for analysing neural signals. It does not require difficult assumptions about the nature of the dimensions underlying cell selectivity, about the distribution and tuning of cell responses or about the way in which information is transmitted and processed. It can be applied to any parameter of neural activity (for example, firing rate or temporal pattern). In this review, we demonstrate the power of Bayesian analysis using examples of visual responses of neurons in primary visual and temporal cortices. We show that interaction between correlation in mean responses to different stimuli (signal) and correlation in response variability within stimuli (noise) can lead to marked improvement of stimulus discrimination using population responses.},
author = {Oram, M W and F\"{o}ldi\'{a}k, P and Perrett, D I and Sengpiel, F},
file = {:Users/alex/Documents/Mendeley Desktop/Oram et al. - 1998 - The 'Ideal Homunculus' decoding neural population signals.pdf:pdf},
issn = {0166-2236},
journal = {Trends in neurosciences},
keywords = {Animals,Models, Neurological,Neurons, Afferent,Neurons, Afferent: physiology,Temporal Lobe,Temporal Lobe: cytology,Temporal Lobe: physiology,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
month = jun,
number = {6},
pages = {259--65},
pmid = {9641539},
title = {{The 'Ideal Homunculus': decoding neural population signals.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9641539},
volume = {21},
year = {1998}
}
@article{Snyder1972,
author = {Snyder, Donald L},
doi = {10.1109/TIT.1972.1054756},
file = {:Users/alex/Documents/Mendeley Desktop/Snyder - 1972 - Filtering and detection for doubly stochastic Poisson processes.pdf:pdf},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
month = jan,
number = {1},
pages = {91--102},
title = {{Filtering and detection for doubly stochastic Poisson processes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1054756},
volume = {18},
year = {1972}
}
@inproceedings{Susemihl2012c,
address = {Klosterneuburg},
author = {Susemihl, Alex and Meir, Ron and Opper, Manfred},
booktitle = {Sensory Coding and Natural Environment},
editor = {Tkacik, Gasper and Bethge, Matthias and Schneidman, Elad},
title = {{Dynamic Stimulus Reconstruction from Noisy Spike Trains}},
year = {2012}
}
@article{Palomar2007,
author = {Palomar, DP and Verd\'{u}, Sergio},
file = {:Users/alex/Documents/Mendeley Desktop/Palomar, Verd\'{u} - 2007 - Representation of mutual information via input estimates.pdf:pdf},
journal = {IEEE Transactions on Information Theory},
number = {2},
pages = {453--470},
title = {{Representation of mutual information via input estimates}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4069154},
volume = {53},
year = {2007}
}
@article{Churchland2010,
abstract = {Neural responses are typically characterized by computing the mean firing rate, but response variability can exist across trials. Many studies have examined the effect of a stimulus on the mean response, but few have examined the effect on response variability. We measured neural variability in 13 extracellularly recorded datasets and one intracellularly recorded dataset from seven areas spanning the four cortical lobes in monkeys and cats. In every case, stimulus onset caused a decline in neural variability. This occurred even when the stimulus produced little change in mean firing rate. The variability decline was observed in membrane potential recordings, in the spiking of individual neurons and in correlated spiking variability measured with implanted 96-electrode arrays. The variability decline was observed for all stimuli tested, regardless of whether the animal was awake, behaving or anaesthetized. This widespread variability decline suggests a rather general property of cortex, that its state is stabilized by an input.},
author = {Churchland, Mark M and Yu, Byron M and Cunningham, John P and Sugrue, Leo P and Cohen, Marlene R and Corrado, Greg S and Newsome, William T and Clark, Andrew M and Hosseini, Paymon and Scott, Benjamin B and Bradley, David C and Smith, Matthew A and Kohn, Adam and Movshon, J Anthony and Armstrong, Katherine M and Moore, Tirin and Chang, Steve W and Snyder, Lawrence H and Lisberger, Stephen G and Priebe, Nicholas J and Finn, Ian M and Ferster, David and Ryu, Stephen I and Santhanam, Gopal and Sahani, Maneesh and Shenoy, Krishna V},
file = {:Users/alex/Documents/Mendeley Desktop/Churchland et al. - 2010 - Stimulus onset quenches neural variability a widespread cortical phenomenon.pdf:pdf},
institution = {Department of Electrical Engineering, Stanford University School of Medicine, Stanford University, Stanford, California, USA. church@stanford.edu},
journal = {Nature Neuroscience},
number = {3},
pages = {369--378},
publisher = {Nature Publishing Group},
title = {{Stimulus onset quenches neural variability: a widespread cortical phenomenon.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2828350\&tool=pmcentrez\&rendertype=abstract},
volume = {13},
year = {2010}
}
@article{Okeefe1971,
author = {O'Keefe, John and Dostrovsky, Jonathan},
journal = {Brain Research},
pages = {171--175},
title = {{The hippocampus as a spatial map . Preliminary evidence from unit activity in the freely-moving rat}},
volume = {34},
year = {1971}
}
@article{Kobayashi2010,
abstract = {Decision making in a noisy and dynamically changing environment is a fundamental task for a cell. To choose appropriate decisions over time, a cell must be equipped with intracellular kinetics that can conduct dynamic and efﬁcient decision making. By using the theory of sequential inference, I demonstrate that dynamic Bayesian decision making can be implemented by an intracellular kinetics with a dual positive feedback structure. I also show that the combination of linear instantaneous and nonlinear stationary sensitivities to the input dominantly contributes to decision making efﬁciency, and that the state-dependent sensitivity change further suppresses noisy response. The statistical principles underlying these two factors are further clariﬁed to be a log-likelihood-dependent quantiﬁcation of the input information and uncertainty-dependent sensitivity control.},
author = {Kobayashi, Tetsuya J.},
doi = {10.1103/PhysRevLett.104.228104},
file = {:Users/alex/Documents/Mendeley Desktop/Kobayashi - 2010 - Implementation of Dynamic Bayesian Decision Making by Intracellular Kinetics.pdf:pdf},
issn = {0031-9007},
journal = {Physical Review Letters},
month = jun,
number = {22},
pages = {1--4},
title = {{Implementation of Dynamic Bayesian Decision Making by Intracellular Kinetics}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.104.228104},
volume = {104},
year = {2010}
}
@article{Thorpe1996,
author = {Thorpe, Simon and Fize, Denis and Marlot, Catherine},
file = {:Users/alex/Documents/Mendeley Desktop/Thorpe, Fize, Marlot - 1996 - Speed of processing in the human visual system.pdf:pdf},
journal = {Nature},
number = {6},
pages = {520--522},
title = {{Speed of processing in the human visual system}},
volume = {381},
year = {1996}
}
@article{Gutfreund2006,
abstract = {Auditory neurons in the owl's external nucleus of the inferior colliculus (ICX) integrate information across frequency channels to create a map of auditory space. This study describes a powerful, sound-driven adaptation of unit responsiveness in the ICX and explores the implications of this adaptation for sensory processing. Adaptation in the ICX was analyzed by presenting lightly anesthetized owls with sequential pairs of dichotic noise bursts. Adaptation occurred in response even to weak, threshold-level sounds and remained strong for more than 100 ms after stimulus offset. Stimulation by one range of sound frequencies caused adaptation that generalized across the entire broad range of frequencies to which these units responded. Identical stimuli were used to test adaptation in the lateral shell of the central nucleus of the inferior colliculus (ICCls), which provides input directly to the ICX. Compared with ICX adaptation, adaptation in the ICCls was substantially weaker, shorter lasting, and far more frequency specific, suggesting that part of the adaptation observed in the ICX was attributable to processes resident to the ICX. The sharp tuning of ICX neurons to space, along with their broad tuning to frequency, allows ICX adaptation to preserve a representation of stimulus location, regardless of the frequency content of the sound. The ICX is known to be a site of visually guided auditory map plasticity. ICX adaptation could play a role in this cross-modal plasticity by providing a short-term memory of the representation of auditory localization cues that could be compared with later-arriving, visual-spatial information from bimodal stimuli.},
author = {Gutfreund, Yoram and Knudsen, Eric I},
doi = {10.1152/jn.01144.2005},
institution = {Department of Neurobiology, Stanford University, Stanford, California, USA. yoramg@tx.technion.ac.il},
issn = {00223077},
journal = {Journal of Neurophysiology},
keywords = {acoustic stimulation,adaptation,animals,auditory perception,auditory perception physiology,brain mapping,electrophysiology,inferior colliculi,inferior colliculi cytology,inferior colliculi physiology,neurons,neurons physiology,photic stimulation,physiological,physiological physiology,pitch perception,pitch perception physiology,space perception,space perception physiology,stereotaxic techniques,strigiformes,strigiformes physiology,visual fields,visual fields physiology,visual perception,visual perception physiology},
number = {2},
pages = {813--25},
pmid = {16707713},
title = {{Adaptation in the auditory space map of the barn owl.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16707713},
volume = {96},
year = {2006}
}
@article{Rao1999,
abstract = {We describe a model of visual processing in which feedback connections from a higher- to a lower-order visual cortical area carry predictions of lower-level neural activities, whereas the feedforward connections carry the residual errors between the predictions and the actual lower-level activities. When exposed to natural images, a hierarchical network of model neurons implementing such a model developed simple-cell-like receptive fields. A subset of neurons responsible for carrying the residual errors showed endstopping and other extra-classical receptive-field effects. These results suggest that rather than being exclusively feedforward phenomena, nonclassical surround effects in the visual cortex may also result from cortico-cortical feedback as a consequence of the visual system using an efficient hierarchical strategy for encoding natural images.},
author = {Rao, R P and Ballard, D H},
doi = {10.1038/4580},
file = {:Users/alex/Documents/Mendeley Desktop/Rao, Ballard - 1999 - Predictive coding in the visual cortex a functional interpretation of some extra-classical receptive-field effects.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Feedback,Forecasting,Models, Neurological,Neural Networks (Computer),Visual Cortex,Visual Cortex: physiology,Visual Pathways,Visual Pathways: physiology},
month = jan,
number = {1},
pages = {79--87},
pmid = {10195184},
title = {{Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10195184},
volume = {2},
year = {1999}
}
@inproceedings{Susemihl2012d,
author = {H\"{a}usler, Chris and Susemihl, Alex},
booktitle = {Bernstein Conference},
title = {{Reconstruction of Natural Image Sequences with Hierarchical Restricted Boltzmann Machines}},
year = {2012}
}
@article{Boerlin2011,
abstract = {Compelling behavioral evidence suggests that humans can make optimal decisions despite the uncertainty inherent in perceptual or motor tasks. A key question in neuroscience is how populations of spiking neurons can implement such probabilistic computations. In this article, we develop a comprehensive framework for optimal, spike-based sensory integration and working memory in a dynamic environment. We propose that probability distributions are inferred spike-per-spike in recurrently connected networks of integrate-and-fire neurons. As a result, these networks can combine sensory cues optimally, track the state of a time-varying stimulus and memorize accumulated evidence over periods much longer than the time constant of single neurons. Importantly, we propose that population responses and persistent working memory states represent entire probability distributions and not only single stimulus values. These memories are reflected by sustained, asynchronous patterns of activity which make relevant information available to downstream neurons within their short time window of integration. Model neurons act as predictive encoders, only firing spikes which account for new information that has not yet been signaled. Thus, spike times signal deterministically a prediction error, contrary to rate codes in which spike times are considered to be random samples of an underlying firing rate. As a consequence of this coding scheme, a multitude of spike patterns can reliably encode the same information. This results in weakly correlated, Poisson-like spike trains that are sensitive to initial conditions but robust to even high levels of external neural noise. This spike train variability reproduces the one observed in cortical sensory spike trains, but cannot be equated to noise. On the contrary, it is a consequence of optimal spike-based inference. In contrast, we show that rate-based models perform poorly when implemented with stochastically spiking neurons.},
author = {Boerlin, Martin and Den\`{e}ve, Sophie},
doi = {10.1371/journal.pcbi.1001080},
file = {:Users/alex/Documents/Mendeley Desktop/Boerlin, Den\`{e}ve - 2011 - Spike-based population coding and working memory.pdf:pdf},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cats,Computational Biology,Computer Simulation,Feedback, Sensory,Feedback, Sensory: physiology,Humans,Memory,Memory: physiology,Models, Neurological,Neurons,Neurons: physiology,Poisson Distribution},
month = feb,
number = {2},
pages = {e1001080},
pmid = {21379319},
title = {{Spike-based population coding and working memory.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3040643\&tool=pmcentrez\&rendertype=abstract},
volume = {7},
year = {2011}
}
@article{Vervaeke2012a,
abstract = {Electrically coupled inhibitory interneurons dynamically control network excitability, yet little is known about how chemical and electrical synapses regulate their activity. Using two-photon glutamate uncaging and dendritic patch-clamp recordings, we found that the dendrites of cerebellar Golgi interneurons acted as passive cables. They conferred distance-dependent sublinear synaptic integration and weakened distal excitatory inputs. Gap junctions were present at a higher density on distal dendrites and contributed substantially to membrane conductance. Depolarization of one Golgi cell increased firing in its neighbors, and inclusion of dendritic gap junctions in interneuron network models enabled distal excitatory synapses to drive network activity more effectively. Our results suggest that dendritic gap junctions counteract sublinear dendritic integration by enabling excitatory synaptic charge to spread into the dendrites of neighboring inhibitory interneurons.},
author = {Vervaeke, Koen and Lorincz, Andrea and Nusser, Zoltan and Silver, R Angus},
doi = {10.1126/science.1215101},
file = {:Users/alex/Documents/Mendeley Desktop/Vervaeke et al. - 2012 - Gap junctions compensate for sublinear dendritic integration in an inhibitory network.pdf:pdf},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Action Potentials,Animals,Axons,Axons: physiology,Cerebellar Cortex,Cerebellar Cortex: cytology,Computer Simulation,Dendrites,Dendrites: physiology,Dendrites: ultrastructure,Electrical Synapses,Electrical Synapses: physiology,Electrical Synapses: ultrastructure,Excitatory Postsynaptic Potentials,Interneurons,Interneurons: physiology,Ion Channels,Ion Channels: physiology,Mice,Mice, Inbred C57BL,Mice, Knockout,Models, Neurological,Nerve Net,Nerve Net: physiology,Nerve Net: ultrastructure,Neural Inhibition,Patch-Clamp Techniques,Synapses,Synapses: physiology,Synaptic Transmission},
month = mar,
number = {6076},
pages = {1624--8},
pmid = {22403180},
title = {{Gap junctions compensate for sublinear dendritic integration in an inhibitory network.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22403180},
volume = {335},
year = {2012}
}
@article{Pillow2011,
abstract = {One of the central problems in systems neuroscience is to understand how neural spike trains convey sensory information. Decoding methods, which provide an explicit means for reading out the information contained in neural spike responses, offer a powerful set of tools for studying the neural coding problem. Here we develop several decoding methods based on point-process neural encoding models, or forward models that predict spike responses to stimuli. These models have concave log-likelihood functions, which allow efficient maximum-likelihood model fitting and stimulus decoding. We present several applications of the encoding model framework to the problem of decoding stimulus information from population spike responses: (1) a tractable algorithm for computing the maximum a posteriori (MAP) estimate of the stimulus, the most probable stimulus to have generated an observed single- or multiple-neuron spike train response, given some prior distribution over the stimulus; (2) a gaussian approximation to the posterior stimulus distribution that can be used to quantify the fidelity with which various stimulus features are encoded; (3) an efficient method for estimating the mutual information between the stimulus and the spike trains emitted by a neural population; and (4) a framework for the detection of change-point times (the time at which the stimulus undergoes a change in mean or variance) by marginalizing over the posterior stimulus distribution. We provide several examples illustrating the performance of these estimators with simulated and real neural data.},
author = {Pillow, Jonathan W and Ahmadian, Yashar and Paninski, Liam},
institution = {Center for Perceptual Systems, University of Texas at Austin, Austin, TX 78751, USA. pillow@mail.utexas.edu},
journal = {Neural Computation},
number = {1},
pages = {1--45},
pmid = {20964538},
publisher = {MIT Press 238 Main St., Suite 500, Cambridge, MA 02142-1046, USA email: journals-info@mit.edu},
title = {{Model-based decoding, information estimation, and change-point detection techniques for multineuron spike trains.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20964538},
volume = {23},
year = {2011}
}
@article{Saunders2012,
abstract = {In many everyday situations, humans must make precise decisions in the presence of uncertain sensory information. For example, when asked to combine information from multiple sources we often assign greater weight to the more reliable information. It has been proposed that statistical-optimality often observed in human perception and decision-making requires that humans have access to the uncertainty of both their senses and their decisions. However, the mechanisms underlying the processes of uncertainty estimation remain largely unexplored. In this paper we introduce a novel visual tracking experiment that requires subjects to continuously report their evolving perception of the mean and uncertainty of noisy visual cues over time. We show that subjects accumulate sensory information over the course of a trial to form a continuous estimate of the mean, hindered only by natural kinematic constraints (sensorimotor latency etc.). Furthermore, subjects have access to a measure of their continuous objective uncertainty, rapidly acquired from sensory information available within a trial, but limited by natural kinematic constraints and a conservative margin for error. Our results provide the first direct evidence of the continuous mean and uncertainty estimation mechanisms in humans that may underlie optimal decision making.},
author = {Saunders, Ian and Vijayakumar, Sethu},
doi = {10.1371/journal.pone.0037547},
file = {:Users/alex/Documents/Mendeley Desktop/Saunders, Vijayakumar - 2012 - Continuous evolution of statistical estimators for optimal decision-making.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
month = jan,
number = {6},
pages = {e37547},
pmid = {22761657},
title = {{Continuous evolution of statistical estimators for optimal decision-making.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3382620\&tool=pmcentrez\&rendertype=abstract},
volume = {7},
year = {2012}
}
@article{Elliott2005,
author = {Elliott, R.J.},
file = {:Users/alex/Documents/Mendeley Desktop/Elliott - 2005 - General smoothing formulas for Markov-modulated Poisson observations.pdf:pdf},
journal = {Automatic Control, IEEE Transactions},
title = {{General smoothing formulas for Markov-modulated Poisson observations}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1492556},
year = {2005}
}
@article{Lochmann2012,
abstract = {Sensory receptive fields (RFs) vary as a function of stimulus properties and measurement methods. Previous stimuli or surrounding stimuli facilitate, suppress, or change the selectivity of sensory neurons' responses. Here, we propose that these spatiotemporal contextual dependencies are signatures of efficient perceptual inference and can be explained by a single neural mechanism, input targeted divisive inhibition. To respond both selectively and reliably, sensory neurons should behave as active predictors rather than passive filters. In particular, they should remove input they can predict ("explain away") from the synaptic inputs to all other neurons. This implies that RFs are constantly and dynamically reshaped by the spatial and temporal context, while the true selectivity of sensory neurons resides in their "predictive field." This approach motivates a reinvestigation of sensory representations and particularly the role and specificity of surround suppression and adaptation in sensory areas.},
author = {Lochmann, Timm and Ernst, Udo a and Den\`{e}ve, Sophie},
doi = {10.1523/JNEUROSCI.0817-11.2012},
file = {:Users/alex/Documents/Mendeley Desktop/Lochmann, Ernst, Den\`{e}ve - 2012 - Perceptual inference predicts contextual modulations of sensory responses.pdf:pdf},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Adaptation, Physiological,Animals,Brain Mapping,Computer Simulation,Humans,Models, Neurological,Neural Inhibition,Neural Inhibition: physiology,Perception,Perception: physiology,Predictive Value of Tests,Sensation,Sensation: physiology,Sensory Receptor Cells,Sensory Receptor Cells: physiology,Synapses,Synapses: physiology},
month = mar,
number = {12},
pages = {4179--95},
pmid = {22442081},
title = {{Perceptual inference predicts contextual modulations of sensory responses.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22442081},
volume = {32},
year = {2012}
}
@article{Le2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1112.6209v3},
author = {Le, Quoc V and Ranzato, Marc Aurelio and Devin, Matthieu and Corrado, Greg S and Ng, Andrew Y},
eprint = {arXiv:1112.6209v3},
file = {:Users/alex/Documents/Mendeley Desktop/Le et al. - 2012 - Building High-level Features Using Large Scale Unsupervised Learning.pdf:pdf},
title = {{Building High-level Features Using Large Scale Unsupervised Learning}},
year = {2012}
}
@article{Mishra2012,
author = {Mishra, J. and Gazzaley, a.},
doi = {10.1523/JNEUROSCI.0867-12.2012},
file = {:Users/alex/Documents/Mendeley Desktop/Mishra, Gazzaley - 2012 - Attention Distributed across Sensory Modalities Enhances Perceptual Performance.pdf:pdf},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = aug,
number = {35},
pages = {12294--12302},
title = {{Attention Distributed across Sensory Modalities Enhances Perceptual Performance}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0867-12.2012},
volume = {32},
year = {2012}
}
@article{Bethge2002,
author = {Bethge, Matthias and Rotermund, David and Pawelzik, Klaus R},
file = {:Users/alex/Documents/Mendeley Desktop/Bethge, Rotermund, Pawelzik - 2002 - Optimal short-term population coding When Fisher information fails.pdf:pdf},
journal = {Neural Computation},
pages = {2317--2351},
title = {{Optimal short-term population coding: When Fisher information fails}},
volume = {14(10)},
year = {2002}
}
@book{Cover1991,
abstract = {Following a brief introduction and overview, early chapters cover the basic algebraic relationships of entropy, relative entropy and mutual information, AEP, entropy rates of stochastics processes and data compression, duality of data compression and the growth rate of wealth. Later chapters explore Kolmogorov complexity, channel capacity, differential entropy, the capacity of the fundamental Gaussian channel, the relationship between information theory and statistics, rate distortion and network information theories. The final two chapters examine the stock market and inequalities in information theory. In many cases the authors actually describe the properties of the solutions before the presented problems.},
author = {Cover, Thomas M and Thomas, Joy A},
booktitle = {Book},
chapter = {Rate Disto},
doi = {10.1177/0022219410375001},
file = {:Users/alex/Documents/Mendeley Desktop/Cover, Thomas - 1991 - Elements of Information Theory.pdf:pdf},
institution = {Wiley},
isbn = {0471062596},
issn = {15384780},
number = {Wiley Series in Telecommunications},
pages = {542},
pmid = {20660925},
publisher = {Wiley},
series = {Wiley Series in Telecommunications},
title = {{Elements of Information Theory}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/0471200611.fmatter\_indsub/summary},
volume = {6},
year = {1991}
}
@article{Puchalla2005,
abstract = {We have explored the manner in which the population of retinal ganglion cells collectively represent the visual world. Ganglion cells in the salamander were recorded simultaneously with a multielectrode array during stimulation with both artificial and natural visual stimuli, and the mutual information that single cells and pairs of cells conveyed about the stimulus was estimated. We found significant redundancy between cells spaced as far as 500 mum apart. When we used standard methods for defining functional types, only ON-type and OFF-type cells emerged as truly independent information channels. Although the average redundancy between nearby cell pairs was moderate, each ganglion cell shared information with many neighbors, so that visual information was represented approximately 10-fold within the ganglion cell population. This high degree of retinal redundancy suggests that design principles beyond coding efficiency may be important at the population level.},
author = {Puchalla, Jason L and Schneidman, Elad and Harris, Robert a and Berry, Michael J},
doi = {10.1016/j.neuron.2005.03.026},
file = {:Users/alex/Documents/Mendeley Desktop/Puchalla et al. - 2005 - Redundancy in the population code of the retina.pdf:pdf},
issn = {0896-6273},
journal = {Neuron},
keywords = {Animals,Models, Neurological,Photic Stimulation,Retinal Ganglion Cells,Retinal Ganglion Cells: physiology,Urodela,Urodela: physiology,Visual Pathways,Visual Pathways: physiology,Visual Perception,Visual Perception: physiology},
month = may,
number = {3},
pages = {493--504},
pmid = {15882648},
title = {{Redundancy in the population code of the retina.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15882648},
volume = {46},
year = {2005}
}
@article{Sharpee2006,
abstract = {Sensory neuroscience seeks to understand how the brain encodes natural environments. However, neural coding has largely been studied using simplified stimuli. In order to assess whether the brain's coding strategy depends on the stimulus ensemble, we apply a new information-theoretic method that allows unbiased calculation of neural filters (receptive fields) from responses to natural scenes or other complex signals with strong multipoint correlations. In the cat primary visual cortex we compare responses to natural inputs with those to noise inputs matched for luminance and contrast. We find that neural filters adaptively change with the input ensemble so as to increase the information carried by the neural response about the filtered stimulus. Adaptation affects the spatial frequency composition of the filter, enhancing sensitivity to under-represented frequencies in agreement with optimal encoding arguments. Adaptation occurs over 40 s to many minutes, longer than most previously reported forms of adaptation.},
author = {Sharpee, Tatyana O and Sugihara, Hiroki and Kurgansky, Andrei V and Rebrik, Sergei P and Stryker, Michael P and Miller, Kenneth D},
doi = {10.1038/nature04519},
file = {:Users/alex/Documents/Mendeley Desktop/Sharpee et al. - 2006 - Adaptive filtering enhances information transmission in visual cortex.pdf:pdf},
issn = {1476-4687},
journal = {Nature},
keywords = {Adaptation,Animals,Cats,Models,Neurological,Photic Stimulation,Physiological,Physiological: physiology,Time Factors,Visual Cortex,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
month = feb,
number = {7079},
pages = {936--42},
pmid = {16495990},
title = {{Adaptive filtering enhances information transmission in visual cortex.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2562720\&tool=pmcentrez\&rendertype=abstract},
volume = {439},
year = {2006}
}
@article{Ecker2011,
author = {Ecker, Alexander S and Berens, Philipp and Tolias, Andreas S and Bethge, Matthias},
doi = {10.1523/JNEUROSCI.2539-11.2011},
file = {:Users/alex/Documents/Mendeley Desktop/Ecker et al. - 2011 - The Effect of Noise Correlations in Populations of Diversely Tuned Neurons.pdf:pdf},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = oct,
number = {40},
pages = {14272--14283},
title = {{The Effect of Noise Correlations in Populations of Diversely Tuned Neurons}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2539-11.2011},
volume = {31},
year = {2011}
}
@article{Beck2011,
abstract = {A simple expression for a lower bound of Fisher information is derived for a network of recurrently connected spiking neurons that have been driven to a noise-perturbed steady state. We call this lower bound linear Fisher information, as it corresponds to the Fisher information that can be recovered by a locally optimal linear estimator. Unlike recent similar calculations, the approach used here includes the effects of nonlinear gain functions and correlated input noise and yields a surprisingly simple and intuitive expression that offers substantial insight into the sources of information degradation across successive layers of a neural network. Here, this expression is used to (1) compute the optimal (i.e., information-maximizing) firing rate of a neuron, (2) demonstrate why sharpening tuning curves by either thresholding or the action of recurrent connectivity is generally a bad idea, (3) show how a single cortical expansion is sufficient to instantiate a redundant population code that can propagate across multiple cortical layers with minimal information loss, and (4) show that optimal recurrent connectivity strongly depends on the covariance structure of the inputs to the network.},
author = {Beck, Jeffrey and Bejjanki, Vikranth R and Pouget, Alexandre},
doi = {10.1162/NECO\_a\_00125},
file = {:Users/alex/Documents/Mendeley Desktop/Beck, Bejjanki, Pouget - 2011 - Insights from a simple expression for linear fisher information in a recurrently connected population of spiking neurons.pdf:pdf},
issn = {1530-888X},
journal = {Neural computation},
keywords = {Action Potentials,Action Potentials: physiology,Models, Neurological,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neurons,Neurons: physiology},
month = jun,
number = {6},
pages = {1484--502},
pmid = {21395435},
title = {{Insights from a simple expression for linear fisher information in a recurrently connected population of spiking neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21395435},
volume = {23},
year = {2011}
}
@article{Freeman2006,
author = {Freeman, Alan W},
file = {:Users/alex/Documents/Mendeley Desktop/Freeman - 2006 - SPATIAL CHARACTERISTICS OF THE CONTRAST CONTROL IN THE CAT ’ S RETINA.pdf:pdf},
number = {5},
title = {{SPATIAL CHARACTERISTICS OF THE CONTRAST CONTROL IN THE CAT ’ S RETINA}},
volume = {31},
year = {2006}
}
@article{Atar2011,
author = {Atar, Rami and Weissman, Tsachy},
doi = {10.1109/ISIT.2011.6034225},
file = {:Users/alex/Documents/Mendeley Desktop/Atar, Weissman - 2011 - Mutual information, relative entropy, and estimation in the Poisson channel.pdf:pdf},
isbn = {978-1-4577-0596-0},
journal = {2011 IEEE International Symposium on Information Theory Proceedings},
keywords = {and phrases,causal estimation,divergence,girsanov transformation,i-mmse,mismatched estimation,mutual information,nonlinear filtering,point processes,poisson channel,relative entropy,shannon theory,statistics},
month = jul,
pages = {708--712},
publisher = {Ieee},
title = {{Mutual information, relative entropy, and estimation in the Poisson channel}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6034225},
year = {2011}
}
@article{Atencio2012,
abstract = {In the primary auditory cortex, spectrotemporal receptive fields (STRFs) are composed of multiple independent components that capture the processing of disparate stimulus aspects by any given neuron. The origin of these multidimensional stimulus filters in the central auditory system is unknown. To determine whether multicomponent STRFs emerge prior to the forebrain, we recorded from single neurons in the main obligatory station of the auditory midbrain, the inferior colliculus. By comparing results of different spike-triggered techniques, we found that the neural responses in the inferior colliculus can be accounted for by a single stimulus filter. This was observed for all temporal response patterns, from strongly phasic to tonic. Our results reveal that spectrotemporal stimulus encoding undergoes a fundamental transformation along the auditory neuraxis, with the emergence of multidimensional receptive fields beyond the auditory midbrain.},
author = {Atencio, Craig Anthony and Sharpee, Tatyana O and Schreiner, Christoph E},
doi = {10.1152/jn.01025.2011},
file = {:Users/alex/Documents/Mendeley Desktop/Atencio, Sharpee, Schreiner - 2012 - Receptive field dimensionality increases from the auditory midbrain to cortex.pdf:pdf},
issn = {1522-1598},
journal = {Journal of neurophysiology},
month = may,
number = {February},
pages = {2594--2603},
pmid = {22323634},
title = {{Receptive field dimensionality increases from the auditory midbrain to cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22323634},
volume = {107},
year = {2012}
}
@article{Bialek2006,
archivePrefix = {arXiv},
arxivId = {arXiv:0712.4381v1},
author = {Bialek, William and van Steveninck, RRR},
eprint = {arXiv:0712.4381v1},
journal = {Theory, 2006 IEEE},
title = {{Efficient representation as a design principle for neural coding and computation}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4036045},
year = {2006}
}
@article{Fill1998,
author = {Fill, James Allen and Fishkind, Donniell E},
file = {:Users/alex/Documents/Mendeley Desktop/Fill, Fishkind - 1998 - The Moore – Penrose Generalized Inverse for Sums of Matrices Background and Main Result.pdf:pdf},
journal = {Education},
keywords = {21218-2682,26756 and dms,96,98,and phrases,baltimore,department of mathematical sciences,edu,grants dms,jhu,jimfill,maryland,moore,morrison,parallel sum,penrose generalized inverse,rank additivity,research supported by nsf,sherman,singular value decomposition,the johns hopkins university,woodbury formula},
pages = {1--14},
title = {{The Moore – Penrose Generalized Inverse for Sums of Matrices Background and Main Result}},
year = {1998}
}
@article{Opper2011,
author = {Opper, Manfred},
file = {:Users/alex/Documents/Mendeley Desktop/Opper - 2011 - Approximate inference for continuous-time Markov processes.pdf:pdf},
isbn = {9780521196765},
journal = {Time},
pages = {131--147},
title = {{Approximate inference for continuous-time Markov processes}},
year = {2011}
}
@article{Park2011,
author = {Park, Mijung and Pillow, Jonathan W},
doi = {10.1371/journal.pcbi.1002219},
editor = {Sporns, Olaf},
file = {:Users/alex/Documents/Mendeley Desktop/Park, Pillow - 2011 - Receptive Field Inference with Localized Priors.pdf:pdf},
issn = {1553-7358},
journal = {PLoS Computational Biology},
month = oct,
number = {10},
pages = {e1002219},
title = {{Receptive Field Inference with Localized Priors}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1002219},
volume = {7},
year = {2011}
}
@article{Smith2006,
abstract = {The auditory neural code must serve a wide range of auditory tasks that require great sensitivity in time and frequency and be effective over the diverse array of sounds present in natural acoustic environments. It has been suggested that sensory systems might have evolved highly efficient coding strategies to maximize the information conveyed to the brain while minimizing the required energy and neural resources. Here we show that, for natural sounds, the complete acoustic waveform can be represented efficiently with a nonlinear model based on a population spike code. In this model, idealized spikes encode the precise temporal positions and magnitudes of underlying acoustic features. We find that when the features are optimized for coding either natural sounds or speech, they show striking similarities to time-domain cochlear filter estimates, have a frequency-bandwidth dependence similar to that of auditory nerve fibres, and yield significantly greater coding efficiency than conventional signal representations. These results indicate that the auditory code might approach an information theoretic optimum and that the acoustic structure of speech might be adapted to the coding capacity of the mammalian auditory system.},
author = {Smith, Evan C and Lewicki, Michael S},
doi = {10.1038/nature04485},
file = {:Users/alex/Documents/Mendeley Desktop/Smith, Lewicki - 2006 - Efficient auditory coding.pdf:pdf},
issn = {1476-4687},
journal = {Nature},
keywords = {Acoustic Stimulation,Adaptation,Algorithms,Animals,Auditory Perception,Auditory Perception: physiology,Cochlea,Cochlea: physiology,Hearing,Hearing: physiology,Humans,Models,Neurological,Noise,Physiological,Physiological: physiology,Sensitivity and Specificity,Sound,Speech,Speech: physiology,Time Factors},
month = feb,
number = {7079},
pages = {978--82},
pmid = {16495999},
title = {{Efficient auditory coding.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16495999},
volume = {439},
year = {2006}
}
@article{Abbott1999,
abstract = {We study the impact of correlated neuronal firing rate variability on the accuracy with which an encoded quantity can be extracted from a population of neurons. Contrary to widespread belief, correlations in the variabilities of neuronal firing rates do not, in general, limit the increase in coding accuracy provided by using large populations of encoding neurons. Furthermore, in some cases, but not all, correlations improve the accuracy of a population code.},
author = {Abbott, L F and Dayan, P},
file = {:Users/alex/Documents/Mendeley Desktop/Abbott, Dayan - 1999 - The effect of correlated variability on the accuracy of a population code.pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Electrophysiology,Models, Biological,Neurons,Neurons: physiology},
month = jan,
number = {1},
pages = {91--101},
pmid = {9950724},
title = {{The effect of correlated variability on the accuracy of a population code.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9950724},
volume = {11},
year = {1999}
}
@article{Stanley1999,
abstract = {A major challenge in studying sensory processing is to understand the meaning of the neural messages encoded in the spiking activity of neurons. From the recorded responses in a sensory circuit, what information can we extract about the outside world? Here we used a linear decoding technique to reconstruct spatiotemporal visual inputs from ensemble responses in the lateral geniculate nucleus (LGN) of the cat. From the activity of 177 cells, we have reconstructed natural scenes with recognizable moving objects. The quality of reconstruction depends on the number of cells. For each point in space, the quality of reconstruction begins to saturate at six to eight pairs of on and off cells, approaching the estimated coverage factor in the LGN of the cat. Thus, complex visual inputs can be reconstructed with a simple decoding algorithm, and these analyses provide a basis for understanding ensemble coding in the early visual pathway.},
author = {Stanley, Garrett B and Li, Fei F and Dan, Yang},
file = {:Users/alex/Documents/Mendeley Desktop/Stanley, Li, Dan - 1999 - Reconstruction of Natural Scenes from Ensemble Responses in the Lateral Geniculate Nucleus.pdf:pdf},
issn = {15292401},
journal = {Journal of Neuroscience},
keywords = {a distributed manner,activity,cat,coded,crucial,ensemble,in a distributed manner,in the activity of,is coded,large neuronal,lation,lgn,natural scenes,reconstruction,responses,this is crucial for,understanding how sensory information,visual system},
number = {18},
pages = {8036--8042},
pmid = {10479703},
publisher = {Soc Neuroscience},
title = {{Reconstruction of Natural Scenes from Ensemble Responses in the Lateral Geniculate Nucleus}},
url = {http://neuro.cjb.net/cgi/content/abstract/19/18/8036},
volume = {19},
year = {1999}
}
@article{Shannon1948,
annote = {        Bell System Technical Journal, vol. 27, pp. 379-423 and 623-656, July and October, 1948.},
author = {Shannon, Claude E.},
file = {:Users/alex/Documents/Mendeley Desktop/Shannon - 1948 - The mathematical theory of communication. 1963.pdf:pdf},
journal = {Bell System Technical Journal},
keywords = {20th Century,Communication,History,Information Theory,Mathematics},
pages = {379--423 and 623--656},
pmid = {9230594},
publisher = {ACM New York, NY, USA},
series = {The mathematical theory of communication},
title = {{The mathematical theory of communication. 1963.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9230594},
volume = {27},
year = {1948}
}
@article{Haslinger2012,
author = {Haslinger, Robert and Pipa, Gordon and Lima, Bruss and Singer, Wolf and Brown, Emery N. and Neuenschwander, Sergio},
doi = {10.1371/journal.pone.0039699},
editor = {Zhang, Li I.},
file = {:Users/alex/Documents/Mendeley Desktop/Haslinger et al. - 2012 - Context Matters The Illusive Simplicity of Macaque V1 Receptive Fields.pdf:pdf},
issn = {1932-6203},
journal = {PLoS ONE},
month = jul,
number = {7},
pages = {e39699},
title = {{Context Matters: The Illusive Simplicity of Macaque V1 Receptive Fields}},
url = {http://dx.plos.org/10.1371/journal.pone.0039699},
volume = {7},
year = {2012}
}
@article{Hahnloser2011,
author = {Hahnloser, Richard H R and Bla, Florian},
doi = {10.1371/Citation},
journal = {October},
number = {10},
title = {{An Efficient Coding Hypothesis Links Sparsity and Selectivity of Neural Responses}},
volume = {6},
year = {2011}
}
@article{Attneave1954,
author = {Attneave, F},
file = {:Users/alex/Documents/Mendeley Desktop/Attneave - 1954 - Some informational aspects of visual perception.pdf:pdf},
issn = {0033-295X},
journal = {Psychological review},
keywords = {Perception,Vision, Ocular},
month = may,
number = {3},
pages = {183--93},
pmid = {13167245},
title = {{Some informational aspects of visual perception.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/13167245},
volume = {61},
year = {1954}
}
@article{Churchland2007a,
abstract = {Large, chronically implanted arrays of microelectrodes are an increasingly common tool for recording from primate cortex and can provide extracellular recordings from many (order of 100) neurons. While the desire for cortically based motor prostheses has helped drive their development, such arrays also offer great potential to advance basic neuroscience research. Here we discuss the utility of array recording for the study of neural dynamics. Neural activity often has dynamics beyond that driven directly by the stimulus. While governed by those dynamics, neural responses may nevertheless unfold differently for nominally identical trials, rendering many traditional analysis methods ineffective. We review recent studies - some employing simultaneous recording, some not - indicating that such variability is indeed present both during movement generation and during the preceding premotor computations. In such cases, large-scale simultaneous recordings have the potential to provide an unprecedented view of neural dynamics at the level of single trials. However, this enterprise will depend not only on techniques for simultaneous recording but also on the use and further development of analysis techniques that can appropriately reduce the dimensionality of the data, and allow visualization of single-trial neural behavior.},
author = {Churchland, Mark M and Yu, Byron M and Sahani, Maneesh and Shenoy, Krishna V},
doi = {10.1016/j.conb.2007.11.001},
issn = {0959-4388},
journal = {Current opinion in neurobiology},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cerebral Cortex,Cerebral Cortex: cytology,Electrodes, Implanted,Humans,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology,Neurophysiology,Neurophysiology: methods},
month = oct,
number = {5},
pages = {609--18},
pmid = {18093826},
title = {{Techniques for extracting single-trial activity patterns from large-scale neural recordings.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2238690\&tool=pmcentrez\&rendertype=abstract},
volume = {17},
year = {2007}
}
@book{Rasmussen2005,
address = {Cambridge, MA},
author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
edition = {1st},
isbn = {0-262-18253-X},
publisher = {MIT Press},
title = {{Gaussian Processes for Machine Learning}},
year = {2005}
}
@article{Kappen2012,
author = {Kappen, Hilbert J. and G\'{o}mez, Vicen\c{c} and Opper, Manfred},
doi = {10.1007/s10994-012-5278-7},
file = {:Users/alex/Documents/Mendeley Desktop/Kappen, G\'{o}mez, Opper - 2012 - Optimal control as a graphical model inference problem.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {approximate inference,belief propagation,cluster variation method,graphical model,kullback-leibler divergence,optimal control,uncontrolled dynamics},
month = feb,
number = {2},
pages = {159--182},
title = {{Optimal control as a graphical model inference problem}},
url = {http://www.springerlink.com/index/10.1007/s10994-012-5278-7},
volume = {87},
year = {2012}
}
@article{Gerwinn2009,
abstract = {The timing of action potentials in spiking neurons depends on the temporal dynamics of their inputs and contains information about temporal fluctuations in the stimulus. Leaky integrate-and-fire neurons constitute a popular class of encoding models, in which spike times depend directly on the temporal structure of the inputs. However, optimal decoding rules for these models have only been studied explicitly in the noiseless case. Here, we study decoding rules for probabilistic inference of a continuous stimulus from the spike times of a population of leaky integrate-and-fire neurons with threshold noise. We derive three algorithms for approximating the posterior distribution over stimuli as a function of the observed spike trains. In addition to a reconstruction of the stimulus we thus obtain an estimate of the uncertainty as well. Furthermore, we derive a spike-by-spike online decoding scheme that recursively updates the posterior with the arrival of each new spike. We use these decoding rules to reconstruct time-varying stimuli represented by a Gaussian process from spike trains of single neurons as well as neural populations.},
author = {Gerwinn, Sebastian and Macke, Jakob and Bethge, Matthias},
file = {:Users/alex/Documents/Mendeley Desktop/Gerwinn, Macke, Bethge - 2009 - Bayesian Population Decoding of Spiking Neurons.pdf:pdf},
institution = {Computational Vision and Neuroscience Group, Max Planck Institute for Biological Cybernetics T\"{u}bingen, Germany.},
journal = {Frontiers in computational neuroscience},
keywords = {approximate inference,bayesian decoding,population coding,spiking neurons},
number = {October},
pages = {14},
publisher = {Frontiers Research Foundation},
title = {{Bayesian Population Decoding of Spiking Neurons}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2790948\&tool=pmcentrez\&rendertype=abstract},
volume = {3},
year = {2009}
}
@article{RahnamaRad2011,
author = {{Rahnama Rad}, Kamiar and Paninski, Liam},
journal = {Advances in Neural Information Processing Systems 24},
pages = {846--854},
title = {{Information Rates and Optimal Decoding in Large Neural Populations}},
url = {http://www.stat.columbia.edu/~liam/research/pubs/kamiar-ss-info.pdf},
year = {2011}
}
@article{Beck2011a,
abstract = {A wide range of computations performed by the nervous system involves a type of probabilistic inference known as marginalization. This computation comes up in seemingly unrelated tasks, including causal reasoning, odor recognition, motor control, visual tracking, coordinate transformations, visual search, decision making, and object recognition, to name just a few. The question we address here is: how could neural circuits implement such marginalizations? We show that when spike trains exhibit a particular type of statistics--associated with constant Fano factors and gain-invariant tuning curves, as is often reported in vivo--some of the more common marginalizations can be achieved with networks that implement a quadratic nonlinearity and divisive normalization, the latter being a type of nonlinear lateral inhibition that has been widely reported in neural circuits. Previous studies have implicated divisive normalization in contrast gain control and attentional modulation. Our results raise the possibility that it is involved in yet another, highly critical, computation: near optimal marginalization in a remarkably wide range of tasks.},
author = {Beck, Jeffrey M and Latham, Peter E and Pouget, Alexandre},
doi = {10.1523/JNEUROSCI.1706-11.2011},
file = {:Users/alex/Documents/Mendeley Desktop/Beck, Latham, Pouget - 2011 - Marginalization in neural circuits with divisive normalization.pdf:pdf},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Computer Simulation,Humans,Models, Neurological,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology,Normal Distribution,Probability},
month = oct,
number = {43},
pages = {15310--9},
pmid = {22031877},
title = {{Marginalization in neural circuits with divisive normalization.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3230133\&tool=pmcentrez\&rendertype=abstract},
volume = {31},
year = {2011}
}
@article{Bialek2007,
archivePrefix = {arXiv},
arxivId = {arXiv:0712.4381v1},
author = {Bialek, William and Tishby, Naftali},
eprint = {arXiv:0712.4381v1},
file = {:Users/alex/Documents/Mendeley Desktop/Bialek, Tishby - 2007 - Efficient representation as a design principle for neural coding and computation.pdf:pdf},
title = {{Efficient representation as a design principle for neural coding and computation}},
year = {2007}
}
@article{Mahajan2009,
abstract = {Optimal design of sequential real-time communication of a Markov source over a noisy channel is investigated. In such a system, the delay between the source output and its reconstruction at the receiver should equal a fixed prespecified amount. An optimal communication strategy must minimize the total expected symbol-by-symbol distortion between the source output and its reconstruction. Design techniques or performance bounds for such real-time communication systems are unknown. In this paper a systematic methodology, based on the concepts of information structures and information states, to search for an optimal real-time communication strategy is presented. This methodology trades off complexity in communication length (linear in contrast to doubly exponential) with complexity in alphabet sizes (doubly exponential in contrast to exponential). As the communication length is usually order of magnitudes bigger than the alphabet sizes, the proposed methodology simplifies the search for an optimal communication strategy. In spite of this simplification, the resultant optimality equations cannot be solved efficiently using existing algorithmic techniques. The main idea is to formulate a zero-delay communication problem as a dynamic team with nonclassical information structure. Then, an appropriate choice of information states converts the dynamic team problem into a centralized stochastic control problem in function space. Thereafter, Markov decision theory is used to derive nested optimality equations for choosing an optimal design. For infinite horizon problems, these optimality equations give rise to a fixed point functional equation. Communication systems with fixed finite delay constraint, a higher-order Markov source, and channels with memory are treated in the same manner after an appropriate expansion of the state space. Thus, this paper presents a comprehensive methodology to study different variations of real-time communication.},
annote = {        From Duplicate 2 (                   Optimal Design of Sequential Real-Time Communication Systems                 - Mahajan, Aditya; Teneketzis, Demosthenis )
                
        
        
      },
author = {Mahajan, Aditya and Teneketzis, Demosthenis},
doi = {10.1109/TIT.2009.2030462},
file = {:Users/alex/Documents/Mendeley Desktop/Mahajan, Teneketzis - 2009 - Optimal design of sequential real-time communication systems.pdf:pdf},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
keywords = {channel coding,dynamic teams,information states,joint source\&\#x2013,nonclassical information structures,real time communication,zero delay communication},
number = {11},
pages = {5317--5338},
title = {{Optimal design of sequential real-time communication systems}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5290272 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5290272},
volume = {55},
year = {2009}
}
@article{Ganguli2011,
author = {Ganguli, Deep and Simoncelli, Eero P},
file = {:Users/alex/Documents/Mendeley Desktop/Ganguli, Simoncelli - 2011 - Implicit encoding of prior probabilities in optimal neural populations.pdf:pdf},
number = {December 2010},
pages = {6--9},
title = {{Implicit encoding of prior probabilities in optimal neural populations}},
year = {2011}
}
@article{Schneidman2003,
author = {Schneidman, Elad and Still, Susanne and Ii, Michael J Berry and Bialek, William},
doi = {10.1103/PhysRevLett.91.238701},
file = {:Users/alex/Documents/Mendeley Desktop/Schneidman et al. - 2003 - Network Information and Connected Correlations.pdf:pdf},
number = {December},
pages = {3--6},
title = {{Network Information and Connected Correlations}},
volume = {1},
year = {2003}
}
@article{Barlow2001,
abstract = {Soon after Shannon defined the concept of redundancy it was suggested that it gave insight into mechanisms of sensory processing, perception, intelligence and inference. Can we now judge whether there is anything in this idea, and can we see where it should direct our thinking? This paper argues that the original hypothesis was wrong in over-emphasizing the role of compressive coding and economy in neuron numbers, but right in drawing attention to the importance of redundancy. Furthermore there is a clear direction in which it now points, namely to the overwhelming importance of probabilities and statistics in neuroscience. The brain has to decide upon actions in a competitive, chance-driven world, and to do this well it must know about and exploit the non-random probabilities and interdependences of objects and events signalled by sensory messages. These are particularly relevant for Bayesian calculations of the optimum course of action. Instead of thinking of neural representations as transformations of stimulus energies, we should regard them as approximate estimates of the probable truths of hypotheses about the current environment, for these are the quantities required by a probabilistic brain working on Bayesian principles.},
author = {Barlow, H},
file = {:Users/alex/Documents/Mendeley Desktop/Barlow - 2001 - Redundancy reduction revisited.pdf:pdf},
issn = {0954-898X},
journal = {Network (Bristol, England)},
keywords = {Artificial Intelligence,Bayes Theorem,Brain,Brain: physiology,Forecasting,Models, Neurological,Models, Statistical},
month = aug,
number = {3},
pages = {241--53},
pmid = {11563528},
title = {{Redundancy reduction revisited.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11563528},
volume = {12},
year = {2001}
}
@article{Sprekeler2011,
abstract = {We develop a group-theoretical analysis of slow feature analysis for the case where the input data are generated by applying a set of continuous transformations to static templates. As an application of the theory, we analytically derive nonlinear visual receptive ﬁelds and show that their optimal stimuli, as well as the orientation and frequency tuning, are in good agreement with previous simulations of complex cells in primary visual cortex (Berkes and Wiskott, 2005). The theory suggests that side and end stopping can be interpreted as a weak breaking of translation invariance. Direction selectivity is also discussed.},
author = {Sprekeler, Henning and Wiskott, Laurenz},
file = {:Users/alex/Documents/Mendeley Desktop/Sprekeler, Wiskott - 2011 - A Theory of Slow Feature Analysis for Transformation-Based Input Signals with an Application to Complex Cells.pdf:pdf},
journal = {Neural Computation},
pages = {303--335},
title = {{A Theory of Slow Feature Analysis for Transformation-Based Input Signals with an Application to Complex Cells}},
volume = {335},
year = {2011}
}
@article{Vincent2010,
author = {Vincent, Pascal and Larochelle, H and Lajoie, I},
file = {:Users/alex/Documents/Mendeley Desktop/Vincent, Larochelle, Lajoie - 2010 - Stacked denoising autoencoders Learning useful representations in a deep network with a local denoising criterion.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {3371--3408},
title = {{Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion}},
url = {http://dl.acm.org/citation.cfm?id=1953011.1953039},
volume = {11},
year = {2010}
}
@article{Segall1975,
author = {Segall, A. and Davis, M. and Kailath, Thomas},
file = {:Users/alex/Documents/Mendeley Desktop/Segall, Davis, Kailath - 1975 - Nonlinear filtering with counting observations.pdf:pdf},
journal = {Information Theory, IEEE Transactions on},
number = {2},
pages = {143--149},
publisher = {IEEE},
title = {{Nonlinear filtering with counting observations}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1055360},
volume = {21},
year = {1975}
}
@article{Tkacik2010,
abstract = {In retina and in cortical slice the collective response of spiking neural populations is well described by "maximum-entropy" models in which only pairs of neurons interact. We asked, how should such interactions be organized to maximize the amount of information represented in population responses? To this end, we extended the linear-nonlinear-Poisson model of single neural response to include pairwise interactions, yielding a stimulus-dependent, pairwise maximum-entropy model. We found that as we varied the noise level in single neurons and the distribution of network inputs, the optimal pairwise interactions smoothly interpolated to achieve network functions that are usually regarded as discrete--stimulus decorrelation, error correction, and independent encoding. These functions reflected a trade-off between efficient consumption of finite neural bandwidth and the use of redundancy to mitigate noise. Spontaneous activity in the optimal network reflected stimulus-induced activity patterns, and single-neuron response variability overestimated network noise. Our analysis suggests that rather than having a single coding principle hardwired in their architecture, networks in the brain should adapt their function to changing noise and stimulus correlations.},
author = {Tkacik, Gasper and Prentice, Jason S and Balasubramanian, Vijay and Schneidman, Elad},
doi = {10.1073/pnas.1004906107},
file = {:Users/alex/Documents/Mendeley Desktop/Tkacik et al. - 2010 - Optimal population coding by noisy spiking neurons.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Models,Nerve Net,Neurological,Neurons,Neurons: physiology,Poisson Distribution},
month = aug,
number = {32},
pages = {14419--24},
pmid = {20660781},
title = {{Optimal population coding by noisy spiking neurons.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2922524\&tool=pmcentrez\&rendertype=abstract},
volume = {107},
year = {2010}
}
@article{Paninski2007,
abstract = {There are two basic problems in the statistical analysis of neural data. The "encoding" problem concerns how information is encoded in neural spike trains: can we predict the spike trains of a neuron (or population of neurons), given an arbitrary stimulus or observed motor response? Conversely, the "decoding" problem concerns how much information is in a spike train, in particular, how well can we estimate the stimulus that gave rise to the spike train? This chapter describes statistical model-based techniques that in some cases provide a unified solution to these two coding problems. These models can capture stimulus dependencies as well as spike history and interneuronal interaction effects in population spike trains, and are intimately related to biophysically based models of integrate-and-fire type. We describe flexible, powerful likelihood-based methods for fitting these encoding models and then for using the models to perform optimal decoding. Each of these (apparently quite difficult) tasks turn out to be highly computationally tractable, due to a key concavity property of the model likelihood. Finally, we return to the encoding problem to describe how to use these models to adaptively optimize the stimuli presented to the cell on a trial-by-trial basis, in order that we may infer the optimal model parameters as efficiently as possible.},
author = {Paninski, Liam and Pillow, Jonathan W and Lewi, Jeremy},
file = {:Users/alex/Documents/Mendeley Desktop/Paninski, Pillow, Lewi - 2007 - Statistical models for neural encoding, decoding, and optimal stimulus design.pdf:pdf},
institution = {Department of Statistics and Center for Theoretical Neuroscience, Columbia University, New York, NY, USA. liam@stat.columbia.edu},
journal = {Progress in Brain Research},
pages = {493--507},
pmid = {17925266},
publisher = {Citeseer},
title = {{Statistical models for neural encoding, decoding, and optimal stimulus design.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17925266},
volume = {165},
year = {2007}
}
@article{Coen-Cagli2012,
author = {Coen-Cagli, Ruben and Dayan, Peter and Schwartz, Odelia},
doi = {10.1371/journal.pcbi.1002405},
editor = {Sporns, Olaf},
file = {:Users/alex/Documents/Mendeley Desktop/Coen-Cagli, Dayan, Schwartz - 2012 - Cortical Surround Interactions and Perceptual Salience via Natural Scene Statistics.pdf:pdf},
issn = {1553-7358},
journal = {PLoS Computational Biology},
month = mar,
number = {3},
pages = {e1002405},
title = {{Cortical Surround Interactions and Perceptual Salience via Natural Scene Statistics}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1002405},
volume = {8},
year = {2012}
}
@article{Csato2001,
abstract = {We develop an approach for a sparse representation for Gaussian Process (GP) models in order to overcome the limitations of GPs caused by large data sets. The method is based on a combination of a Bayesian online algorithm together with a sequential construction of a relevant subsample of the data which fully specifies the prediction of the model. Experimental results on toy examples and large real-world datasets indicate the efficiency of the approach.},
author = {Csat\'{o}, Lehel and Opper, Manfred},
editor = {Leen, Todd K and Dietterich, Thomas G and Tresp, Volker},
journal = {Advances in Neural Information Processing Systems 13},
keywords = {mathematical computing sciences not elsewhere clas},
pages = {444--450},
publisher = {Massachusetts Institute of Technology Press (MIT Press)},
title = {{Sparse representation for Gaussian process models}},
url = {http://eprints.aston.ac.uk/1293/},
volume = {13},
year = {2001}
}
@article{Ecker2010,
abstract = {Correlated trial-to-trial variability in the activity of cortical neurons is thought to reflect the functional connectivity of the circuit. Many cortical areas are organized into functional columns, in which neurons are believed to be densely connected and to share common input. Numerous studies report a high degree of correlated variability between nearby cells. We developed chronically implanted multitetrode arrays offering unprecedented recording quality to reexamine this question in the primary visual cortex of awake macaques. We found that even nearby neurons with similar orientation tuning show virtually no correlated variability. Our findings suggest a refinement of current models of cortical microcircuit architecture and function: Either adjacent neurons share only a few percent of their inputs or, alternatively, their activity is actively decorrelated.},
author = {Ecker, Alexander S and Berens, Philipp and Keliris, Georgios A and Bethge, Matthias and Logothetis, Nikos K and Tolias, Andreas S},
file = {:Users/alex/Documents/Mendeley Desktop/Ecker et al. - 2010 - Decorrelated neuronal firing in cortical microcircuits.pdf:pdf},
institution = {Max Planck Institute for Biological Cybernetics, 72076 T\"{u}bingen, Germany.},
journal = {Science},
number = {5965},
pages = {584--587},
pmid = {20110506},
publisher = {AAAS},
title = {{Decorrelated neuronal firing in cortical microcircuits.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20110506},
volume = {327},
year = {2010}
}
@article{Dear1993,
author = {Dear, S.P. and Simmons, J.A. and Fritz, J.},
file = {:Users/alex/Documents/Mendeley Desktop//Dear, Simmons, Fritz - 1993 - A Possible Neural Basis for Representations of Acoustic Scenes in Auditory Cortex of the Big Brown Bat.pdf:pdf},
journal = {Nature},
number = {6438},
pages = {620--623},
publisher = {Nature Publishing Group},
title = {{A Possible Neural Basis for Representations of Acoustic Scenes in Auditory Cortex of the Big Brown Bat}},
url = {http://www.nature.com/nature/journal/v364/n6438/abs/364620a0.html},
volume = {364},
year = {1993}
}
@article{Merhav2011,
author = {Merhav, N},
journal = {Information Theory, IEEE Transactions on},
number = {6},
pages = {3887--3898},
publisher = {IEEE},
title = {{Optimum estimation via gradients of partition functions and information measures: a statistical-mechanical perspective}},
volume = {57},
year = {2011}
}
@article{Knierim1995,
abstract = {Previous studies have shown that hippocampal place fields are controlled by the salient sensory cues in the environment, in that rotation of the cues causes an equal rotation of the place fields. We trained rats to forage for food pellets in a gray cylinder with a single salient directional cue, a white card covering 90 degrees of the cylinder wall. Half of the rats were disoriented before being placed in the cylinder, in order to disrupt their internal sense of direction. The other half were not disoriented before being placed in the cylinder; for these rats, there was presumably a consistent relationship between the cue card and their internal direction sense. We subsequently recorded hippocampal place cells and thalamic head direction cells from both groups of rats as they moved in the cylinder; between some sessions the cylinder and cue card were rotated to a new direction. All rats were disoriented before recording. Under these conditions, the cue card had much weaker control over the place fields and head direction cells in the rats that had been disoriented during training than in the rats that had not been disoriented. For the former group, the place fields often rotated relative to the cue card or completely changed their firing properties between sessions. In all recording sessions, the head direction cells and place cells were strongly coupled. It appears that the strength of cue control over place cells and head direction cells depends on the rat's learned perception of the stability of the cues.},
author = {Knierim, James J and Kudrimoti, Hemant S and McNaughton, Bruce L},
journal = {The Journal of Neuroscience},
number = {3},
pages = {1648--1659},
title = {{Place cells, head direction cells, and the learning of landmark stability}},
url = {http://www.jneurosci.org/content/15/3/1648.abstract},
volume = {15},
year = {1995}
}
@article{Atick2011,
abstract = {The sensory pathways of animals are well adapted to processing a special class of signals, namely stimuli from the animal's environment. An important fact about natural stimuli is that they are typically very redundant and hence the sampled representation of these signals formed by the array of sensory cells is inefficient. One could argue for some animals and pathways, as we do in this review, that efficiency of information representation in the nervous system has several evolutionary advantages. Consequently, one might expect that much of the processing in the early levels of these sensory pathways could be dedicated towards recoding incoming signals into a more efficient form. In this review, we explore the principle of efficiency of information representation as a design principle for sensory processing. We give a preliminary discussion on how this principle could be applied in general to predict neural processing and then discuss concretely some neural systems where it recently has been shown to be successful. In particular, we examine the fly's LMC coding strategy and the mammalian retinal coding in the spatial, temporal and chromatic domains.},
author = {Atick, Joseph J},
doi = {10.3109/0954898X.2011.638888},
file = {:Users/alex/Documents/Mendeley Desktop/Atick - 2011 - Could information theory provide an ecological theory of sensory processing.pdf:pdf},
issn = {1361-6536},
journal = {Network (Bristol, England)},
keywords = {Animals,Ecology,Ecology: methods,Ecology: trends,Humans,Information Theory,Neural Networks (Computer),Neural Pathways,Neural Pathways: physiology},
month = jan,
number = {1-4},
pages = {4--44},
pmid = {22149669},
title = {{Could information theory provide an ecological theory of sensory processing?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22149669},
volume = {22},
year = {2011}
}
@article{Chow2012,
author = {Chow, Siu-Fai and Wick, Stuart D. and Riecke, Hermann},
doi = {10.1371/journal.pcbi.1002398},
editor = {Gutkin, Boris S.},
file = {:Users/alex/Documents/Mendeley Desktop/Chow, Wick, Riecke - 2012 - Neurogenesis Drives Stimulus Decorrelation in a Model of the Olfactory Bulb.pdf:pdf},
issn = {1553-7358},
journal = {PLoS Computational Biology},
month = mar,
number = {3},
pages = {e1002398},
title = {{Neurogenesis Drives Stimulus Decorrelation in a Model of the Olfactory Bulb}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1002398},
volume = {8},
year = {2012}
}
@inproceedings{Susemihl2011b,
abstract = {Many aspects of human perception can be understood as arising from probabilistic inference. Particularly when integrating cues from different sources with different reliability humans have been observed to integrate these cues optimally in a Bayesian sense [1, 2]. Claims of optimality of the observed behavior abound, although little theoretical work has been done to establish this. Here we propose an analytical model of stimulus reconstruction from noisy spike trains, in which we are able to solve for the mean squared error of an ideal Bayesian observer. Furthermore, this is done in a time-dependent fashion which allows us to study the evolution of the error. We present analytical results for a simplified labeled-line population coding model of Poisson spiking neurons with Gaussian-shaped tuning functions. By drawing the stimuli from a Gaussian process distribution and under the assumption of strongly overlapping tuning functions, we are able to derive a time-dependent filtering scheme for the reconstruction of the stimulus. From that we find a differential equation for the mean squared error of an ideal Bayesian observer. This has been studied via direct simulation of the spike trains and a mean-field approximation. We observe the existence of a finite optimal tuning width for both cases. This has been reported before for the case of static stimuli [3]. Our findings are also consistent with findings of tuning function adaptation in primates [4]. The present work seeks to provide a comprehensive and solid approach to- wards neural coding in a dynamic framework. We believe a thorough analysis of neural coding could shed light on phenomena as tuning function adaptation and shapes of tuning functions in the context of Bayes optimality. The approach is also very flexible so that a number of systems could be investigated with it. There are some natural extensions to the present work, namely the inclusion of more complex spike generation mechanisms and the analysis of high-dimensional cases. This work provides a first step towards a mathematical and ecological theory of sensory processing.},
author = {Susemihl, Alex and Opper, Manfred},
booktitle = {Bernstein Conference},
file = {:Users/alex/Documents/Mendeley Desktop/Susemihl, Opper - 2011 - An Analytical Study of Population Coding of Dynamic Stimuli.pdf:pdf},
number = {0},
pages = {2011},
title = {{An Analytical Study of Population Coding of Dynamic Stimuli}},
url = {http://www.frontiersin.org/10.3389/conf.fncom.2011.53.00157/event\_abstract},
volume = {5},
year = {2011}
}
@inproceedings{Park2011a,
author = {Park, Il Memming},
booktitle = {Advances in Neural Information Processing Systems},
file = {:Users/alex/Documents/Mendeley Desktop/Park - 2011 - Bayesian Spike-Triggered Covariance Analysis.pdf:pdf},
pages = {1--9},
title = {{Bayesian Spike-Triggered Covariance Analysis}},
volume = {24},
year = {2011}
}
@article{Churchland2012,
author = {Churchland, Mark M. and Cunningham, John P. and Kaufman, Matthew T. and Foster, Justin D. and Nuyujukian, Paul and Ryu, Stephen I. and Shenoy, Krishna V.},
doi = {10.1038/nature11129},
file = {:Users/alex/Documents/Mendeley Desktop/Churchland et al. - 2012 - Neural population dynamics during reaching.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
month = jun,
publisher = {Nature Publishing Group},
title = {{Neural population dynamics during reaching}},
url = {http://www.nature.com/doifinder/10.1038/nature11129},
year = {2012}
}
@article{Still2012,
author = {Still, Susanne and Sivak, David A and Bell, Anthony J and Crooks, Gavin E},
doi = {10.1103/PhysRevLett.109.120604},
file = {:Users/alex/Documents/Mendeley Desktop/Still et al. - 2012 - Thermodynamics of Prediction.pdf:pdf},
journal = {Physical Review Letters},
number = {120604},
pages = {1--5},
title = {{Thermodynamics of Prediction}},
volume = {109},
year = {2012}
}
@article{Rahnama,
author = {Rahnama, Kamiar and Liam, Rad},
file = {:Users/alex/Documents/Mendeley Desktop/Rahnama, Liam - Unknown - Information Rates and Optimal Decoding in Large Neural Populations.pdf:pdf},
pages = {1--9},
title = {{Information Rates and Optimal Decoding in Large Neural Populations}}
}
@article{Vasilkov2012,
author = {Vasilkov, Viacheslav and Tikidji-Hamburyan, Ruben},
doi = {10.1103/PhysRevLett.108.138104},
file = {:Users/alex/Documents/Mendeley Desktop/Vasilkov, Tikidji-Hamburyan - 2012 - Accurate Detection of Interaural Time Differences by a Population of Slowly Integrating Neurons.pdf:pdf},
issn = {0031-9007},
journal = {Physical Review Letters},
month = mar,
number = {13},
pages = {1--5},
title = {{Accurate Detection of Interaural Time Differences by a Population of Slowly Integrating Neurons}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.108.138104},
volume = {108},
year = {2012}
}
@article{Seung1993,
abstract = {In many neural systems, sensory information is distributed throughout a population of neurons. We study simple neural network models for extracting this information. The inputs to the networks are the stochastic responses of a population of sensory neurons tuned to directional stimuli. The performance of each network model in psychophysical tasks is compared with that of the optimal maximum likelihood procedure. As a model of direction estimation in two dimensions, we consider a linear network that computes a population vector. Its performance depends on the width of the population tuning curves and is maximal for width, which increases with the level of background activity. Although for narrowly tuned neurons the performance of the population vector is significantly inferior to that of maximum likelihood estimation, the difference between the two is small when the tuning is broad. For direction discrimination, we consider two models: a perceptron with fully adaptive weights and a network made by adding an adaptive second layer to the population vector network. We calculate the error rates of these networks after exhaustive training to a particular direction. By testing on the full range of possible directions, the extent of transfer of training to novel stimuli can be calculated. It is found that for threshold linear networks the transfer of perceptual learning is nonmonotonic. Although performance deteriorates away from the training stimulus, it peaks again at an intermediate angle. This nonmonotonicity provides an important psychophysical test of these models.},
author = {Seung, H S and Sompolinsky, H},
file = {:Users/alex/Documents/Mendeley Desktop/Seung, Sompolinsky - 1993 - Simple models for reading neuronal population codes.pdf:pdf},
isbn = {1074910753},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Afferent,Afferent: physiology,Animals,Humans,Likelihood Functions,Models,Nerve Net,Neurons,Orientation,Orientation: physiology,Perception,Perception: physiology,Stochastic Processes,Theoretical},
month = nov,
number = {22},
pages = {10749--53},
pmid = {8248166},
title = {{Simple models for reading neuronal population codes.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=47855\&tool=pmcentrez\&rendertype=abstract},
volume = {90},
year = {1993}
}
@article{Lesica2008,
abstract = {The transformation of auditory information from the cochlea to the cortex is a highly nonlinear process. Studies using tone stimuli have revealed that changes in even the most basic parameters of the auditory stimulus can alter neural response properties; for example, a change in stimulus intensity can cause a shift in a neuron's preferred frequency. However, it is not yet clear how such nonlinearities contribute to the processing of spectrotemporal features in complex sounds. Here, we use spectrotemporal receptive fields (STRFs) to characterize the effects of stimulus intensity on feature selectivity in the mammalian inferior colliculus (IC). At low intensities, we find that STRFs are relatively simple, typically consisting of a single excitatory region, indicating that the neural response is simply a reflection of the stimulus amplitude at the preferred frequency. In contrast, we find that STRFs at high intensities typically consist of a combination of an excitatory region and one or more inhibitory regions, often in a spectrotemporally inseparable arrangement, indicating selectivity for complex auditory features. We show that a linear-nonlinear model with the appropriate STRF can predict neural responses to stimuli with a fixed intensity, and we demonstrate that a simple extension of the model with an intensity-dependent STRF can predict responses to stimuli with varying intensity. These results illustrate the complexity of auditory feature selectivity in the IC, but also provide encouraging evidence that the prediction of nonlinear responses to complex stimuli is a tractable problem.},
author = {Lesica, Nicholas a and Grothe, Benedikt},
doi = {10.1523/JNEUROSCI.0073-08.2008},
file = {:Users/alex/Documents/Mendeley Desktop/Lesica, Grothe - 2008 - Dynamic spectrotemporal feature selectivity in the auditory midbrain.pdf:pdf},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Animals,Dose-Response Relationship, Radiation,Evoked Potentials, Auditory, Brain Stem,Evoked Potentials, Auditory, Brain Stem: physiolog,Gerbillinae,Inferior Colliculi,Inferior Colliculi: cytology,Models, Neurological,Neurons,Neurons: physiology,Nonlinear Dynamics,Predictive Value of Tests,Sound Spectrography},
month = may,
number = {21},
pages = {5412--21},
pmid = {18495875},
title = {{Dynamic spectrotemporal feature selectivity in the auditory midbrain.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18495875},
volume = {28},
year = {2008}
}
@article{Lesica2008a,
abstract = {In this study, we investigate the ability of the mammalian auditory pathway to adapt its strategy for temporal processing under natural stimulus conditions. We derive temporal receptive fields from the responses of neurons in the inferior colliculus to vocalization stimuli with and without additional ambient noise. We find that the onset of ambient noise evokes a change in receptive field dynamics that corresponds to a change from bandpass to lowpass temporal filtering. We show that these changes occur within a few hundred milliseconds of the onset of the noise and are evident across a range of overall stimulus intensities. Using a simple model, we illustrate how these changes in temporal processing exploit differences in the statistical properties of vocalizations and ambient noises to increase the information in the neural response in a manner consistent with the principles of efficient coding.},
author = {Lesica, Nicholas a and Grothe, Benedikt},
doi = {10.1371/journal.pone.0001655},
file = {:Users/alex/Documents/Mendeley Desktop/Lesica, Grothe - 2008 - Efficient temporal processing of naturalistic sounds.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
keywords = {Acoustic Stimulation,Animals,Auditory Pathways,Auditory Perception,Auditory Perception: physiology,Noise,Sound},
month = jan,
number = {2},
pages = {e1655},
pmid = {18301738},
title = {{Efficient temporal processing of naturalistic sounds.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2249929\&tool=pmcentrez\&rendertype=abstract},
volume = {3},
year = {2008}
}
@article{Faisal2009,
abstract = {Most behavioral tasks have time constraints for successful completion, such as catching a ball in flight. Many of these tasks require trading off the time allocated to perception and action, especially when only one of the two is possible at any time. In general, the longer we perceive, the smaller the uncertainty in perceptual estimates. However, a longer perception phase leaves less time for action, which results in less precise movements. Here we examine subjects catching a virtual ball. Critically, as soon as subjects began to move, the ball became invisible. We study how subjects trade-off sensory and movement uncertainty by deciding when to initiate their actions. We formulate this task in a probabilistic framework and show that subjects' decisions when to start moving are statistically near optimal given their individual sensory and motor uncertainties. Moreover, we accurately predict individual subject's task performance. Thus we show that subjects in a natural task are quantitatively aware of how sensory and motor variability depend on time and act so as to minimize overall task variability.},
author = {Faisal, a Aldo and Wolpert, Daniel M},
doi = {10.1152/jn.90974.2008},
file = {:Users/alex/Documents/Mendeley Desktop/Faisal, Wolpert - 2009 - Near optimal combination of sensory and motor uncertainty in time during a naturalistic perception-action task.pdf:pdf},
issn = {0022-3077},
journal = {Journal of neurophysiology},
keywords = {Adult,Decision Making,Decision Making: physiology,Feedback,Humans,Learning,Learning: physiology,Motion Perception,Motion Perception: physiology,Movement,Movement: physiology,Orientation,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,Reaction Time: physiology,Task Performance and Analysis,Time Factors,Time Perception,Time Perception: physiology,Uncertainty,User-Computer Interface,Young Adult},
month = apr,
number = {4},
pages = {1901--12},
pmid = {19109455},
title = {{Near optimal combination of sensory and motor uncertainty in time during a naturalistic perception-action task.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2695629\&tool=pmcentrez\&rendertype=abstract},
volume = {101},
year = {2009}
}
@article{Shriki2012,
abstract = {Understanding how populations of neurons encode sensory information is a major goal of systems neuroscience. Attempts to answer this question have focused on responses measured over several hundred milliseconds, a duration much longer than that frequently used by animals to make decisions about the environment. How reliably sensory information is encoded on briefer time scales, and how best to extract this information, is unknown. Although it has been proposed that neuronal response latency provides a major cue for fast decisions in the visual system, this hypothesis has not been tested systematically and in a quantitative manner. Here we use a simple 'race to threshold' readout mechanism to quantify the information content of spike time latency of primary visual (V1) cortical cells to stimulus orientation. We find that many V1 cells show pronounced tuning of their spike latency to stimulus orientation and that almost as much information can be extracted from spike latencies as from firing rates measured over much longer durations. To extract this information, stimulus onset must be estimated accurately. We show that the responses of cells with weak tuning of spike latency can provide a reliable onset detector. We find that spike latency information can be pooled from a large neuronal population, provided that the decision threshold is scaled linearly with the population size, yielding a processing time of the order of a few tens of milliseconds. Our results provide a novel mechanism for extracting information from neuronal populations over the very brief time scales in which behavioral judgments must sometimes be made.},
author = {Shriki, Oren and Kohn, Adam and Shamir, Maoz},
doi = {10.1371/journal.pcbi.1002536},
file = {:Users/alex/Documents/Mendeley Desktop/Shriki, Kohn, Shamir - 2012 - Fast coding of orientation in primary visual cortex.pdf:pdf},
issn = {1553-7358},
journal = {PLoS computational biology},
month = jun,
number = {6},
pages = {e1002536},
pmid = {22719237},
title = {{Fast coding of orientation in primary visual cortex.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3375217\&tool=pmcentrez\&rendertype=abstract},
volume = {8},
year = {2012}
}
@article{Churchland2007,
abstract = {Large, chronically implanted arrays of microelectrodes are an increasingly common tool for recording from primate cortex and can provide extracellular recordings from many (order of 100) neurons. While the desire for cortically based motor prostheses has helped drive their development, such arrays also offer great potential to advance basic neuroscience research. Here we discuss the utility of array recording for the study of neural dynamics. Neural activity often has dynamics beyond that driven directly by the stimulus. While governed by those dynamics, neural responses may nevertheless unfold differently for nominally identical trials, rendering many traditional analysis methods ineffective. We review recent studies - some employing simultaneous recording, some not - indicating that such variability is indeed present both during movement generation and during the preceding premotor computations. In such cases, large-scale simultaneous recordings have the potential to provide an unprecedented view of neural dynamics at the level of single trials. However, this enterprise will depend not only on techniques for simultaneous recording but also on the use and further development of analysis techniques that can appropriately reduce the dimensionality of the data, and allow visualization of single-trial neural behavior.},
author = {Churchland, Mark M and Yu, Byron M and Sahani, Maneesh and Shenoy, Krishna V},
doi = {10.1016/j.conb.2007.11.001},
file = {:Users/alex/Documents/Mendeley Desktop/Churchland et al. - 2007 - Techniques for extracting single-trial activity patterns from large-scale neural recordings.pdf:pdf},
institution = {Neurosciences Program and Department of Electrical Engineering, Stanford University, CISX, 330 Serra Mall, Stanford, CA 94305-4075, United States. church@stanford.edu},
issn = {0959-4388},
journal = {Current Opinion in Neurobiology},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Cerebral Cortex,Cerebral Cortex: cytology,Electrodes,Humans,Implanted,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology,Neurophysiology,Neurophysiology: methods},
month = oct,
number = {5},
pages = {609--618},
pmid = {18093826},
publisher = {Elsevier},
title = {{Techniques for extracting single-trial activity patterns from large-scale neural recordings.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18093826 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2238690\&tool=pmcentrez\&rendertype=abstract},
volume = {17},
year = {2007}
}
@article{Corbett,
author = {Corbett, Elaine A and Perreault, Eric J and K\"{o}rding, Konrad P},
file = {:Users/alex/Documents/Mendeley Desktop/Corbett, Perreault, K\"{o}rding - Unknown - Mixture of time -warped trajectory models for movement decoding.pdf:pdf},
pages = {1--9},
title = {{Mixture of time -warped trajectory models for movement decoding}}
}
@article{William1989,
author = {William, W},
file = {:Users/alex/Documents/Mendeley Desktop/William - 1989 - Updating inverse a.pdf:pdf},
keywords = {1,65-02,65f05,ams,concerning various applications of,expo-,history,matrix perturbations,matrix updates,mos,response to gene golub,s suggestion that an,sherman-morrison,sitory paper be prepared,subject classifications,the sherman-morrison,this paper is in,woodbury},
number = {2},
pages = {221--239},
title = {{Updating inverse a}},
volume = {31},
year = {1989}
}
@article{Lochmann2011,
abstract = {Perception is about making sense, that is, understanding what events in the outside world caused the sensory observations. Consistent with this intuition, many aspects of human behavior confronting noise and ambiguity are well explained by principles of causal inference. Extending these insights, recent studies have applied the same powerful set of tools to perceptual processing at the neural level. According to these approaches, microscopic neural structures solve elementary probabilistic tasks and can be combined to construct hierarchical predictive models of the sensory input. This framework suggests that variability in neural responses reflects the inherent uncertainty associated with sensory interpretations and that sensory neurons are active predictors rather than passive filters of their inputs. Causal inference can account parsimoniously and quantitatively for non-linear dynamical properties in single synapses, single neurons and sensory receptive fields.},
author = {Lochmann, Timm and Deneve, Sophie},
doi = {10.1016/j.conb.2011.05.018},
file = {:Users/alex/Documents/Mendeley Desktop/Lochmann, Deneve - 2011 - Neural processing as causal inference.pdf:pdf},
issn = {1873-6882},
journal = {Current opinion in neurobiology},
keywords = {Action Potentials,Action Potentials: physiology,Cerebral Cortex,Cerebral Cortex: cytology,Concept Formation,Concept Formation: physiology,Humans,Models, Neurological,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Perception,Perception: physiology,Probability,Sensation,Sensory Receptor Cells,Sensory Receptor Cells: physiology},
month = oct,
number = {5},
pages = {774--81},
pmid = {21742484},
publisher = {Elsevier Ltd},
title = {{Neural processing as causal inference.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21742484},
volume = {21},
year = {2011}
}
@article{Meier2011,
author = {Meier, Philip and Flister, Erik and Reinagel, Pamela},
doi = {10.1167/11.3.22.Introduction},
file = {:Users/alex/Documents/Mendeley Desktop/Meier, Flister, Reinagel - 2011 - Collinear features impair visual detection by rats.pdf:pdf},
journal = {Journal of Vision},
keywords = {1,10,11,1167,16,2011,22,3,citation,collinear,collinear features impair visual,content,contrast gain,detection,detection by rats,discrimination,doi,e,flister,http,journal of vision,journalofvision,learning,meier,org,p,reinagel,spatial vision,visual cognition,www},
pages = {1--16},
title = {{Collinear features impair visual detection by rats}},
url = {http://ww.w.journalofvision.org/content/11/3/22.short},
volume = {11},
year = {2011}
}
@article{Kfir2012,
author = {Kfir, Yoav and Renan, Ittai and Schneidman, Elad and Segev, Ronen},
doi = {10.1371/journal.pone.0033149},
editor = {Krapp, Holger G.},
file = {:Users/alex/Documents/Mendeley Desktop/Kfir et al. - 2012 - The Natural Variation of a Neural Code.pdf:pdf},
issn = {1932-6203},
journal = {PLoS ONE},
month = mar,
number = {3},
pages = {e33149},
title = {{The Natural Variation of a Neural Code}},
url = {http://dx.plos.org/10.1371/journal.pone.0033149},
volume = {7},
year = {2012}
}
@article{Stephens2008,
archivePrefix = {arXiv},
arxivId = {arXiv:0806.2694v1},
author = {Stephens, GJ and Mora, Thierry and Tkacik, Gasper},
eprint = {arXiv:0806.2694v1},
file = {:Users/alex/Documents/Mendeley Desktop/Stephens, Mora, Tkacik - 2008 - Thermodynamics of natural images.pdf:pdf},
journal = {Arxiv preprint arXiv:0806.2694},
title = {{Thermodynamics of natural images}},
url = {http://arxiv.org/abs/0806.2694},
year = {2008}
}
@article{Wang2005,
abstract = {It has been well documented that neurons in the auditory cortex of anaesthetized animals generally display transient responses to acoustic stimulation, and typically respond to a brief stimulus with one or fewer action potentials. The number of action potentials evoked by each stimulus usually does not increase with increasing stimulus duration. Such observations have long puzzled researchers across disciplines and raised serious questions regarding the role of the auditory cortex in encoding ongoing acoustic signals. Contrary to these long-held views, here we show that single neurons in both primary (area A1) and lateral belt areas of the auditory cortex of awake marmoset monkeys (Callithrix jacchus) are capable of firing in a sustained manner over a prolonged period of time, especially when they are driven by their preferred stimuli. In contrast, responses become more transient or phasic when auditory cortex neurons respond to non-preferred stimuli. These findings suggest that when the auditory cortex is stimulated by a sound, a particular population of neurons fire maximally throughout the duration of the sound. Responses of other, less optimally driven neurons fade away quickly after stimulus onset. This results in a selective representation of the sound across both neuronal population and time.},
author = {Wang, Xiaoqin and Lu, Thomas and Snider, Ross K and Liang, Li},
doi = {10.1038/nature03565},
file = {:Users/alex/Documents/Mendeley Desktop/Wang et al. - 2005 - Sustained firing in auditory cortex evoked by preferred stimuli.pdf:pdf},
issn = {1476-4687},
journal = {Nature},
keywords = {Acoustic Stimulation,Action Potentials,Action Potentials: physiology,Animals,Auditory Cortex,Auditory Cortex: cytology,Auditory Cortex: physiology,Auditory Perception,Auditory Perception: physiology,Callithrix,Callithrix: physiology,Models, Neurological,Neurons,Neurons: physiology,Sound,Time Factors,Wakefulness,Wakefulness: physiology},
month = may,
number = {7040},
pages = {341--6},
pmid = {15902257},
title = {{Sustained firing in auditory cortex evoked by preferred stimuli.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15902257},
volume = {435},
year = {2005}
}
@book{Robert2007,
address = {New York, NY},
author = {Robert, Christian P.},
edition = {2nd},
isbn = {9780387715988},
pages = {602},
publisher = {Springer},
title = {{The Bayesian Choice: From Decision-Theoretical Foundations to Computational Implementation}},
year = {2007}
}
@article{Vogels2011a,
abstract = {Cortical neurons receive balanced excitatory and inhibitory synaptic currents. Such a balance could be established and maintained in an experience-dependent manner by synaptic plasticity at inhibitory synapses. We show that this mechanism provides an explanation for the sparse firing patterns observed in response to natural stimuli and fits well with a recently observed interaction of excitatory and inhibitory receptive field plasticity. The introduction of inhibitory plasticity in suitable recurrent networks provides a homeostatic mechanism that leads to asynchronous irregular network states. Further, it can accommodate synaptic memories with activity patterns that become indiscernible from the background state but can be reactivated by external stimuli. Our results suggest an essential role of inhibitory plasticity in the formation and maintenance of functional cortical circuitry.},
author = {Vogels, T P and Sprekeler, H and Zenke, F and Clopath, C and Gerstner, W},
doi = {10.1126/science.1211095},
file = {:Users/alex/Documents/Mendeley Desktop/Vogels et al. - 2011 - Inhibitory plasticity balances excitation and inhibition in sensory pathways and memory networks.pdf:pdf},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Afferent Pathways,Afferent Pathways: physiology,Memory,Memory: physiology,Models, Neurological,Nerve Net,Neural Inhibition,Neural Inhibition: physiology,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Synaptic Transmission,Synaptic Transmission: physiology},
month = dec,
number = {6062},
pages = {1569--73},
pmid = {22075724},
title = {{Inhibitory plasticity balances excitation and inhibition in sensory pathways and memory networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22075724},
volume = {334},
year = {2011}
}
@article{Freeman1991,
abstract = {Impulse rate was recorded from X- and Y-type ganglion cells in the cat's retina. The stimuli were stationary gratings for which luminance varied sinusoidally with distance across the stimulus, and amplitude varied sinusoidally in time. Y cell fundamental and second harmonic responses recorded at medium to high spatial frequencies advanced in phase with increasing contrast, an effect attributable to the contrast gain control. As spatial frequency increased to the highest value capable of evoking a second harmonic response, the phase of this response became retarded, indicating that the contrast gain control was losing its effect. This result showed that the spatial resolution of the contrast gain control is very close to that of the Y cell's rectifying subunits. The observations strongly suggest that the contrast gain control has its effect early in retinal image processing.},
author = {Freeman, a W},
issn = {0042-6989},
journal = {Vision research},
keywords = {Animals,Cats,Contrast Sensitivity,Contrast Sensitivity: physiology,Mathematics,Models, Biological,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Retinal Ganglion Cells,Retinal Ganglion Cells: physiology,Time Factors},
month = jan,
number = {5},
pages = {775--85},
pmid = {2035263},
title = {{Spatial characteristics of the contrast gain control in the cat's retina.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/2035263},
volume = {31},
year = {1991}
}
@article{Vincent2008,
address = {New York, New York, USA},
author = {Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine},
doi = {10.1145/1390156.1390294},
file = {:Users/alex/Documents/Mendeley Desktop/Vincent et al. - 2008 - Extracting and composing robust features with denoising autoencoders.pdf:pdf},
isbn = {9781605582054},
journal = {Proceedings of the 25th international conference on Machine learning - ICML '08},
pages = {1096--1103},
publisher = {ACM Press},
title = {{Extracting and composing robust features with denoising autoencoders}},
url = {http://portal.acm.org/citation.cfm?doid=1390156.1390294},
year = {2008}
}
@article{Hager1989,
abstract = {The Sherman-Morrison-Woodbury formulas relate the inverse of a matrix after a small- rank perturbation to the inverse of the original matrix. The history of these fomulas is presented and various applications to statistics, networks, structural analysis, asymptotic analysis, optimization, and partial differential equations are discussed. The Sherman-Morrison-Woodbury formulas express the inverse of a matrix after a small rank perturbation in terms of the inverse of the original matrix. This paper surveys the history of these formulas and we examine some applications where these formulas are helpful.},
author = {Hager, William W.},
journal = {Society for Industrial and Applied Mathematics},
keywords = {1,65-02,65f05,ams,concerning various applications of,expo-,history,matrix perturbations,matrix updates,mos,response to gene golub,s suggestion that an,sherman-morrison,sitory paper be prepared,subject classifications,the sherman-morrison,this paper is in,woodbury},
number = {2},
pages = {221--239},
title = {{Updating the Inverse of a Matrix}},
volume = {31},
year = {1989}
}
@inproceedings{marszalek09,
author = {Marsza$\backslash$lek, Marcin and Laptev, Ivan and Schmid, Cordelia},
booktitle = {IEEE Conference on Computer Vision \& Pattern Recognition},
title = {{Actions in Context}},
year = {2009}
}
@article{Whitesides2004,
author = {Whitesides, G. M.},
doi = {10.1002/adma.200400767},
file = {:Users/alex/Documents/Mendeley Desktop/Whitesides - 2004 - Whitesides' Group Writing a Paper.pdf:pdf},
issn = {0935-9648},
journal = {Advanced Materials},
month = aug,
number = {15},
pages = {1375--1377},
title = {{Whitesides' Group: Writing a Paper}},
url = {http://doi.wiley.com/10.1002/adma.200400767},
volume = {16},
year = {2004}
}
@book{Pardoux2010,
author = {Pardoux, E},
file = {:Users/alex/Documents/Mendeley Desktop//Pardoux - 2010 - Stochastic partial differential equations and filtering of diffusion processes Stochastic Partial Differential Equations a n d Filtering of Diffusion Processes.pdf:pdf},
isbn = {1744250790883},
number = {January 2012},
pages = {37--41},
title = {{Stochastic partial differential equations and filtering of diffusion processes Stochastic Partial Differential Equations a n d Filtering of Diffusion Processes}},
year = {2010}
}
@article{Olshausen1996,
abstract = {Natural images contain characteristic statistical regularities that set them apart from purely random images. Understanding what these regularities are can enable natural images to be coded more efficiently. In this paper, we describe some of the forms of structure that are contained in natural images, and we show how these are related to the response properties of neurons at early stages of the visual system. Many of the important forms of structure require higher-order (i.e. more than linear, pairwise) statistics to characterize, which makes models based on linear Hebbian learning, or principal components analysis, inappropriate for finding efficient codes for natural images. We suggest that a good objective for an efficient coding of natural scenes is to maximize the sparseness of the representation, and we show that a network that learns sparse codes of natural scenes succeeds in developing localized, oriented, bandpass receptive fields similar to those in the mammalian striate cortex.},
author = {Olshausen, B A and Field, D J},
doi = {10.1088/0954-898X/7/2/014},
file = {:Users/alex/Documents/Mendeley Desktop/Olshausen, Field - 1996 - Natural image statistics and efficient coding.pdf:pdf},
issn = {0954898X},
journal = {Network},
number = {2},
pages = {333--339},
pmid = {16754394},
publisher = {Informa Clin Med},
title = {{Natural image statistics and efficient coding}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16754394},
volume = {7},
year = {1996}
}
@article{Oram1998,
abstract = {Information processing in the nervous system involves the activity of large populations of neurons. It is possible, however, to interpret the activity of relatively small numbers of cells in terms of meaningful aspects of the environment. 'Bayesian inference' provides a systematic and effective method of combining information from multiple cells to accomplish this. It is not a model of a neural mechanism (neither are alternative methods, such as the population vector approach) but a tool for analysing neural signals. It does not require difficult assumptions about the nature of the dimensions underlying cell selectivity, about the distribution and tuning of cell responses or about the way in which information is transmitted and processed. It can be applied to any parameter of neural activity (for example, firing rate or temporal pattern). In this review, we demonstrate the power of Bayesian analysis using examples of visual responses of neurons in primary visual and temporal cortices. We show that interaction between correlation in mean responses to different stimuli (signal) and correlation in response variability within stimuli (noise) can lead to marked improvement of stimulus discrimination using population responses.},
author = {Oram, M W and F\"{o}ldi\'{a}k, P and Perrett, D I and Sengpiel, F},
issn = {0166-2236},
journal = {Trends in neurosciences},
keywords = {Animals,Models, Neurological,Neurons, Afferent,Neurons, Afferent: physiology,Temporal Lobe,Temporal Lobe: cytology,Temporal Lobe: physiology,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
month = jun,
number = {6},
pages = {259--65},
pmid = {9641539},
title = {{The 'Ideal Homunculus': decoding neural population signals.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9641539},
volume = {21},
year = {1998}
}
@article{Toyoizumi2006,
author = {Toyoizumi, Taro and Aihara, Kazuyuki and Amari, Shun-ichi},
doi = {10.1103/PhysRevLett.97.098102},
file = {:Users/alex/Documents/Mendeley Desktop/Toyoizumi, Aihara, Amari - 2006 - Fisher Information for Spike-Based Population Decoding.pdf:pdf},
issn = {0031-9007},
journal = {Physical Review Letters},
month = aug,
number = {9},
pages = {1--4},
title = {{Fisher Information for Spike-Based Population Decoding}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.97.098102},
volume = {97},
year = {2006}
}
@article{Pouget2000,
abstract = {Information is encoded in the brain by populations or clusters of cells, rather than by single cells. This encoding strategy is known as population coding. Here we review the standard use of population codes for encoding and decoding information, and consider how population codes can be used to support neural computations such as noise removal and nonlinear mapping. More radical ideas about how population codes may directly represent information about stimulus uncertainty are also discussed.},
author = {Pouget, a and Dayan, P and Zemel, R},
doi = {10.1038/35039062},
file = {:Users/alex/Documents/Mendeley Desktop/Pouget, Dayan, Zemel - 2000 - Information processing with population codes.pdf:pdf},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
keywords = {Animals,Brain,Brain: physiology,Humans,Likelihood Functions,Mental Processes,Mental Processes: physiology,Models, Neurological,Neurons,Neurons: physiology,Nonlinear Dynamics},
month = nov,
number = {2},
pages = {125--32},
pmid = {11252775},
title = {{Information processing with population codes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11252775},
volume = {1},
year = {2000}
}
@article{Petreanu2012,
author = {Petreanu, Leopoldo and Gutnisky, Diego a. and Huber, Daniel and Xu, Ning-long and O’Connor, Dan H. and Tian, Lin and Looger, Loren and Svoboda, Karel},
doi = {10.1038/nature11321},
file = {:Users/alex/Documents/Mendeley Desktop/Petreanu et al. - 2012 - Activity in motor–sensory projections reveals distributed coding in somatosensation.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
month = aug,
number = {7415},
pages = {299--303},
publisher = {Nature Publishing Group},
title = {{Activity in motor–sensory projections reveals distributed coding in somatosensation}},
url = {http://www.nature.com/doifinder/10.1038/nature11321},
volume = {489},
year = {2012}
}
@article{Zhang1999a,
abstract = {Sensory and motor variables are typically represented by a population of broadly tuned neurons. A coarser representation with broader tuning can often improve coding accuracy, but sometimes the accuracy may also improve with sharper tuning. The theoretical analysis here shows that the relationship between tuning width and accuracy depends crucially on the dimension of the encoded variable. A general rule is derived for how the Fisher information scales with the tuning width, regardless of the exact shape of the tuning function, the probability distribution of spikes, and allowing some correlated noise between neurons. These results demonstrate a universal dimensionality effect in neural population coding.},
author = {Zhang, Kechen and Sejnowski, TJ Terrence J.},
file = {:Users/alex/Documents/Mendeley Desktop/Zhang, Sejnowski - 1999 - Neuronal tuning To sharpen or broaden.pdf:pdf},
institution = {Computational Neurobiology Lab, The Salk Institute, 10010 North Torrey Pines Road, La Jolla, CA 92038, USA. zhang@salk.edu},
journal = {Neural Computation},
keywords = {artifacts,electrophysiology,models,neurological,neurons,neurons physiology},
number = {1},
pages = {75--84},
pmid = {9950722},
publisher = {MIT Press},
title = {{Neuronal tuning: To sharpen or broaden?}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/089976699300016809 http://www.ncbi.nlm.nih.gov/pubmed/9950722},
volume = {11},
year = {1999}
}
@article{Ernst2002,
abstract = {When a person looks at an object while exploring it with their hand, vision and touch both provide information for estimating the properties of the object. Vision frequently dominates the integrated visual-haptic percept, for example when judging size, shape or position, but in some circumstances the percept is clearly affected by haptics. Here we propose that a general principle, which minimizes variance in the final estimate, determines the degree to which vision or haptics dominates. This principle is realized by using maximum-likelihood estimation to combine the inputs. To investigate cue combination quantitatively, we first measured the variances associated with visual and haptic estimation of height. We then used these measurements to construct a maximum-likelihood integrator. This model behaved very similarly to humans in a visual-haptic task. Thus, the nervous system seems to combine visual and haptic information in a fashion that is similar to a maximum-likelihood integrator. Visual dominance occurs when the variance associated with visual estimation is lower than that associated with haptic estimation.},
author = {Ernst, Marc O and Banks, Martin S},
doi = {10.1038/415429a},
file = {:Users/alex/Documents/Mendeley Desktop/Ernst, Banks - 2002 - Humans integrate visual and haptic information in a statistically optimal fashion.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
keywords = {Adult,Humans,Models, Neurological,Sensory Thresholds,Size Perception,Size Perception: physiology,Touch,Touch: physiology},
month = jan,
number = {6870},
pages = {429--33},
pmid = {11807554},
title = {{Humans integrate visual and haptic information in a statistically optimal fashion.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11807554},
volume = {415},
year = {2002}
}
@article{Chopin2012a,
abstract = {What humans perceive depends in part on what they have previously experienced [1, 2]. After repeated exposure to one stimulus, adaptation takes place in the form of a negative correlation between the current percept and the last displayed stimuli [3-10]. Previous work has shown that this negative dependence can extend to a few minutes in the past [5, 11, 12], but the precise extent and nature of the dependence in vision is still unknown. In two experiments based on orientation judgments, we reveal a positive dependence of a visual percept with stimuli presented remotely in the past, unexpectedly and in contrast to what is known for the recent past. Previous theories of adaptation have postulated that the visual system attempts to calibrate itself relative to an ideal norm [13, 14] or to the recent past [5, 7, 10, 15, 16]. We propose instead that the remote past is used to estimate the world's statistics and that this estimate becomes the reference. According to this new framework, adaptation is predictive: the most likely forthcoming percept is the one that helps the statistics of the most recent percepts match that of the remote past.},
author = {Chopin, Adrien and Mamassian, Pascal},
doi = {10.1016/j.cub.2012.02.021},
file = {:Users/alex/Documents/Mendeley Desktop/Chopin, Mamassian - 2012 - Predictive Properties of Visual Adaptation.pdf:pdf},
issn = {1879-0445},
journal = {Current Biology},
month = feb,
pages = {1--5},
pmid = {22386314},
publisher = {Elsevier Ltd},
title = {{Predictive Properties of Visual Adaptation}},
url = {http://dx.doi.org/10.1016/j.cub.2012.02.021 http://www.ncbi.nlm.nih.gov/pubmed/22386314},
year = {2012}
}
@article{Susemihl2012a,
author = {Susemihl, Alex and Meir, Ron and Opper, Manfred},
file = {:Users/alex/Documents/Mendeley Desktop/Susemihl, Meir, Opper - 2012 - Dynamic State Estimation Based on Poisson Spike Trains - Towards a Theory of Optimal Encoding (submitted for rewiew).pdf:pdf},
journal = {Journal of Statistical Mechanics: Theory and Experiment},
title = {{Dynamic State Estimation Based on Poisson Spike Trains - Towards a Theory of Optimal Encoding (submitted for rewiew)}},
year = {2012}
}
@inproceedings{Susemihl2012b,
author = {Susemihl, Alex and Meir, Ron and Opper, Manfred},
booktitle = {Bernstein Conference},
title = {{Dynamic Stimulus Reconstruction from Noisy Spike Trains}},
year = {2012}
}
@article{O'Keefe1971,
author = {O'Keefe, J and Dostrovsky, J},
file = {:Users/alex/Documents/Mendeley Desktop/O'Keefe, Dostrovsky - 1971 - The hippocampus as a spatial map Preliminary evidence from unit activity in the freely-moving rat.pdf:pdf},
journal = {Brain Research},
pages = {171--175},
title = {{The hippocampus as a spatial map: Preliminary evidence from unit activity in the freely-moving rat.}},
url = {http://psycnet.apa.org/psycinfo/1972-08318-001},
volume = {34},
year = {1971}
}
@article{Simoncelli2001,
abstract = {It has long been assumed that sensory neurons are adapted, through both evolutionary and developmental processes, to the statistical properties of the signals to which they are exposed. Attneave (1954)Barlow (1961) proposed that information theory could provide a link between environmental statistics and neural responses through the concept of coding efficiency. Recent developments in statistical modeling, along with powerful computational tools, have enabled researchers to study more sophisticated statistical models for visual images, to validate these models empirically against large sets of data, and to begin experimentally testing the efficient coding hypothesis for both individual neurons and populations of neurons.},
annote = {        From Duplicate 1 (                   Natural image statistics and neural representation                 - Simoncelli, Eero P; Olshausen, Bruno A )
                
        From Duplicate 1 (                           Natural image statistics and neural representation                         - Simoncelli, Eero P; Olshausen, Bruno A )
                
        
        
        
        
      },
author = {Simoncelli, Eero P and Olshausen, Bruno A},
doi = {10.1146/annurev.neuro.24.1.1193},
file = {:Users/alex/Documents/Mendeley Desktop/Simoncelli, Olshausen - 2001 - Natural image statistics and neural representation.pdf:pdf},
issn = {0147006X},
journal = {Annual Review of Neuroscience},
keywords = {1954,1961,and barlow,are exposed,attneave,both evolutionary and developmental,efficient coding,independence,long been assumed that,of the,processes,proposed that,redundancy reduction,s abstract it has,sensory neurons are adapted,signals to which they,through,to the statistical properties,visual cortex},
number = {1},
pages = {1193--1216},
pmid = {11520932},
publisher = {Annual Reviews 4139 El Camino Way, PO Box 10139, Palo Alto, CA 94303-0139, USA},
title = {{Natural image statistics and neural representation}},
url = {http://www.annualreviews.org/doi/abs/10.1146/annurev.neuro.24.1.1193},
volume = {24},
year = {2001}
}
@article{Ramirez2011,
abstract = {Birdsong is comprised of rich spectral and temporal organization, which might be used for vocal perception. To quantify how this structure could be used, we have reconstructed birdsong spectrograms by combining the spike trains of zebra finch auditory midbrain neurons with information about the correlations present in song. We calculated maximum a posteriori estimates of song spectrograms using a generalized linear model of neuronal responses and a series of prior distributions, each carrying different amounts of statistical information about zebra finch song. We found that spike trains from a population of mesencephalicus lateral dorsalis (MLd) neurons combined with an uncorrelated Gaussian prior can estimate the amplitude envelope of song spectrograms. The same set of responses can be combined with Gaussian priors that have correlations matched to those found across multiple zebra finch songs to yield song spectrograms similar to those presented to the animal. The fidelity of spectrogram reconstructions from MLd responses relies more heavily on prior knowledge of spectral correlations than temporal correlations. However, the best reconstructions combine MLd responses with both spectral and temporal correlations.},
author = {Ramirez, Alexandro D and Ahmadian, Yashar and Schumacher, Joseph and Schneider, David and Woolley, Sarah M N and Paninski, Liam},
doi = {10.1523/JNEUROSCI.3256-10.2011},
issn = {1529-2401},
journal = {The Journal of neuroscience},
keywords = {Acoustic Stimulation,Action Potentials,Action Potentials: physiology,Animal,Animal: physiology,Animals,Computer-Assisted,Electrophysiology,Finches,Mesencephalon,Mesencephalon: physiology,Neurons,Neurons: physiology,Signal Processing,Sound Spectrography,Sound Spectrography: methods,Vocalization},
month = mar,
number = {10},
pages = {3828--42},
pmid = {21389238},
title = {{Incorporating naturalistic correlation structure improves spectrogram reconstruction from neuronal activity in the songbird auditory midbrain.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3273872\&tool=pmcentrez\&rendertype=abstract},
volume = {31},
year = {2011}
}
@article{Barlow1961,
author = {Barlow, H.B.},
file = {:Users/alex/Documents/Mendeley Desktop/Barlow - 1961 - Possible principles underlying the transformation of sensory messages.pdf:pdf},
journal = {Sensory communication},
pages = {217--234},
title = {{Possible principles underlying the transformation of sensory messages}},
url = {http://www.trin.cam.ac.uk/horacebarlow/21.pdf},
year = {1961}
}
@book{Oxford2011,
abstract = {In many areas of human endeavour, the systems involved are not available for direct measurement. Instead, by combining mathematical models for a system's evolution with partial observations of its evolving state, we can make reasonable inferences about it. The increasing complexity of the modern world makes this analysis and synthesis of high-volume data an essential feature in many real-world problems. The celebrated Kalman-Bucy filter, designed for linear dynamical systems with linearly structured measurements, is the most famous Bayesian filter. Its generalizations to nonlinear systems and/or observations are collectively referred to as nonlinear filtering (NLF), an extension of the Bayesian framework to the estimation, prediction, and interpolation of nonlinear stochastic dynamics. NLF uses a stochastic model to make inferences about an evolving system and is a theoretically optimal algorithm. The breadth of its applications, firmly established and still emerging, is simply astounding. Early uses such as cryptography, tracking, and guidance were mostly of a military nature. Since then, the scope has exploded. It includes the study of global climate, estimating the state of the economy, identifying tumours using non-invasive methods, and much more. The Oxford Handbook of Nonlinear Filtering is the first comprehensive written resource for the subject. It contains classical and recent results and applications, with contributions from 58 authors. Collated into 10 parts, it covers the foundations of nonlinear filtering, connections to stochastic partial differential equations, stability and asymptotic analysis, estimation and control, approximation theory and numerical methods for solving the nonlinear filtering problem (including particle methods). It also contains a part dedicated to the application of nonlinear filtering to several problems in mathematical finance. Contributors to this volume - R. Atar - Department of Electrical Engineering, Technion, Haifa, Israel A. Bensoussan - University of Texas at Dallas, USA H. A. P. Blom - National Aerospace Laboratory NLR, The Netherlands A. Budhiraja - University of North Carolina, USA M. Cakanyldirim - University of Texas at Dallas, USA P. Y. Chigansky - The Weizmann Institute of Science J. M. C. Clark - Imperial College London, UK D. Crisan - Imperial College London, UK M. Davis - Imperial College London, UK A. Doucet - The Institute of Statistical Mathematics, Tokyo, Japan. T. Duncan - University of Kansas, USA R. J. Elliott - University of Calgary, Australia R. Frey - Universitat Leipzig, Leipzig F. Le Gland - IRISA/INRIA, France B. Grigelionis - Lithuania F. Gustaffson - Linkoping University, Sweden M. Hairer - University of Warwick, UK R. Van Handel - Princeton University, USA A. J. Heunis - University of Waterloo, Canada A. M. Johansen - University of Warwick, UK R. Karlsson - Linkoping University, Sweden M. L. Kleptsyna - Universite du Maine, France N. V. Krylov - University of Minnesota, USA H. Kunita - Fukuoka, Japan T. Kurtz - University of Wisconsin- Madison, USA H. Kushner - Brown University, USA R. Lipster - Tel Aviv University, Israel C. Litterer - Mathematical Institute, Oxford, UK T. Lyons - Mathematical Institute, Oxford, UK S. V. Lototsky - University of Southern California, USA M. Chaleyat-Maurel - Universite Paris Descartes 45, Paris Hong Miao - Colorado State University, USA R. Mikulevicius - USC Department of Mathematics, Los Angeles, USA G. Milstein - Ural State University, Russia V. Monbet - Universite de Bretagne-Sud, France P. del Moral - Universite Bordeaux 1, France G. Nappo - University "La Sapienza", Italy N. J. Newton - University of Essex, UK F. Patras - Universite de Nice, France H. Pham - Universites Paris 6- Paris 7, France B. Rozovski? - Brown University, USA S. Rubenthaler - Universite de Nice, France W. J. Runggaldier - Universita degli Studi di Padova, Italy T.B. Schon - Linkoping University, Sweden L. C. Scott - University of Missouri at Kansas City, USA S. P. Sethi - University of Texas at Dallas, USA Y. Bar-Shalom - University of Connecticut, USA W. Stannat - Fachbereich Mathematik A. Stuart - University of Warwick, UK V.-D. Tran - Universite de Bretagne-Sud, France M. Tretyakov - University of Leicester, UK A. Y. Veretennikov - University of Leeds, UK R. Vinter - Imperial College London, UK J. Voss - University of Warwick, UK Zhenyu Wu - University of Saskatchewan, Canada J. Xiong - Mathematics Department, Knoxville, USA O. Zeitouni - University of Minnesota, USA Y. Zeng - University of Missouri at Kansas City, USA},
address = {Oxford},
author = {Crisan, Dan and Rozovskii, Boris},
publisher = {Oxford University Press},
title = {{The Oxford Handbook of Nonlinear Filtering}},
url = {http://econpapers.repec.org/RePEc:oxp:obooks:9780199532902},
year = {2011}
}
@article{Huys2007,
abstract = {Uncertainty coming from the noise in its neurons and the ill-posed nature of many tasks plagues neural computations. Maybe surprisingly, many studies show that the brain manipulates these forms of uncertainty in a probabilistically consistent and normative manner, and there is now a rich theoretical literature on the capabilities of populations of neurons to implement computations in the face of uncertainty. However, one major facet of uncertainty has received comparatively little attention: time. In a dynamic, rapidly changing world, data are only temporarily relevant. Here, we analyze the computational consequences of encoding stimulus trajectories in populations of neurons. For the most obvious, simple, instantaneous encoder, the correlations induced by natural, smooth stimuli engender a decoder that requires access to information that is nonlocal both in time and across neurons. This formally amounts to a ruinous representation. We show that there is an alternative encoder that is computationally and representationally powerful in which each spike contributes independent information; it is independently decodable, in other words. We suggest this as an appropriate foundation for understanding time-varying population codes. Furthermore, we show how adaptation to temporal stimulus statistics emerges directly from the demands of simple decoding.},
author = {Huys, Quentin J M and Zemel, Richard S and Natarajan, Rama and Dayan, Peter},
file = {:Users/alex/Documents/Mendeley Desktop/Huys et al. - 2007 - Fast population coding.pdf:pdf},
institution = {Gatsby Computational Neuroscience Unit, University College London, London WC1N 3AR, UK. qhuys@cantab.net},
journal = {Neural Computation},
number = {2},
pages = {404--441},
pmid = {17206870},
publisher = {MIT Press},
title = {{Fast population coding.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17206870},
volume = {19},
year = {2007}
}
@article{Gollisch2010a,
abstract = {We rely on our visual system to cope with the vast barrage of incoming light patterns and to extract features from the scene that are relevant to our well-being. The necessary reduction of visual information already begins in the eye. In this review, we summarize recent progress in understanding the computations performed in the vertebrate retina and how they are implemented by the neural circuitry. A new picture emerges from these findings that helps resolve a vexing paradox between the retina's structure and function. Whereas the conventional wisdom treats the eye as a simple prefilter for visual images, it now appears that the retina solves a diverse set of specific tasks and provides the results explicitly to downstream brain areas.},
author = {Gollisch, Tim and Meister, Markus},
doi = {10.1016/j.neuron.2009.12.009},
file = {:Users/alex/Documents/Mendeley Desktop/Gollisch, Meister - 2010 - Eye smarter than scientists believed neural computations in circuits of the retina.pdf:pdf},
issn = {1097-4199},
journal = {Neuron},
keywords = {Animals,Computational Biology,Computational Biology: manpower,Computational Biology: methods,Humans,Nerve Net,Nerve Net: physiology,Neurology,Neurology: methods,Neurology: trends,Retina,Retina: physiology,Visual Pathways,Visual Pathways: physiology,Visual Perception,Visual Perception: physiology},
month = jan,
number = {2},
pages = {150--64},
pmid = {20152123},
publisher = {Elsevier Inc.},
title = {{Eye smarter than scientists believed: neural computations in circuits of the retina.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20152123},
volume = {65},
year = {2010}
}
@article{Tkacik2010a,
abstract = {The visual system is challenged with extracting and representing behaviorally relevant information contained in natural inputs of great complexity and detail. This task begins in the sensory periphery: retinal receptive fields and circuits are matched to the first and second-order statistical structure of natural inputs. This matching enables the retina to remove stimulus components that are predictable (and therefore uninformative), and primarily transmit what is unpredictable (and therefore informative). Here we show that this design principle applies to more complex aspects of natural scenes, and to central visual processing. We do this by classifying high-order statistics of natural scenes according to whether they are uninformative vs. informative. We find that the uninformative ones are perceptually nonsalient, while the informative ones are highly salient, and correspond to previously identified perceptual mechanisms whose neural basis is likely central. Our results suggest that the principle of efficient coding not only accounts for filtering operations in the sensory periphery, but also shapes subsequent stages of sensory processing that are sensitive to high-order image statistics.},
author = {Tkacik, Gasper and Prentice, Jason S and Victor, Jonathan D and Balasubramanian, Vijay},
doi = {10.1073/pnas.0914916107},
file = {:Users/alex/Documents/Mendeley Desktop/Tkacik et al. - 2010 - Local statistics in natural scenes predict the saliency of synthetic textures.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Humans,Light,Retina,Retina: physiology,Visual Fields,Visual Perception},
month = oct,
number = {42},
pages = {18149--54},
pmid = {20923876},
title = {{Local statistics in natural scenes predict the saliency of synthetic textures.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2964243\&tool=pmcentrez\&rendertype=abstract},
volume = {107},
year = {2010}
}
@article{Atick1992,
abstract = {The sensory pathways of animals are well adapted to processing a special class of signals, namely stimuli from the animal's environment. An important fact about natural stimuli is that they are typically very redundant and hence the sampled representation of these signals formed by the array of sensory cells is inefficient. One could argue for some animals and pathways, as we do in this review, that efficiency of information representation in the nervous system has several evolutionary advantages. Consequently, one might expect that much of the processing in the early levels of these sensory pathways could be dedicated towards recoding incoming signals into a more efficient form. In this review, we explore the principle of efficiency of information representation as a design principle for sensory processing. We give a preliminary discussion on how this principle could be applied in general to predict neural processing and then discuss concretely some neural systems where it recently has been shown to be successful. In particular, we examine the fly's LMC coding strategy and the mammalian retinal coding in the spatial, temporal and chromatic domains.},
author = {Atick, Joseph J},
doi = {10.3109/0954898X.2011.638888},
issn = {1361-6536},
journal = {Network: Computation in neural systems},
month = jan,
number = {2},
pages = {213--251},
pmid = {22149669},
title = {{Could information theory provide an ecological theory of sensory processing?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22149669},
volume = {3},
year = {1992}
}
@article{Levy2012,
abstract = {Biological networks are ubiquitously modular, a feature that is believed to be essential for the enhancement of their functional capacities. Here, we have used a simple modular in vitro design to examine the possibility that modularity enhances network functionality in the context of input representation. We cultured networks of cortical neurons obtained from newborn rats in vitro on substrate-integrated multi-electrode arrays, forcing the network to develop two well-defined modules of neural populations that are coupled by a narrow canal. We measured the neural activity, and examined the capacity of each module to individually classify (i.e. represent) spatially distinct electrical stimuli and propagate input-specific activity features to their downstream coupled counterpart. We show that, although each of the coupled modules maintains its autonomous functionality, a significant enhancement of representational capacity is achieved when the system is observed as a whole. We interpret our results in terms of a relative decorrelation effect imposed by weak coupling between modules.},
author = {Levy, Ofri and Ziv, Noam E and Marom, Shimon},
doi = {10.1111/j.1460-9568.2012.08094.x},
file = {:Users/alex/Documents/Mendeley Desktop/Levy, Ziv, Marom - 2012 - Enhancement of neural representation capacity by modular architecture in networks of cortical neurons.pdf:pdf},
issn = {1460-9568},
journal = {The European journal of neuroscience},
keywords = {classification,modularity,multi-electrode array,neural network,representation scheme},
month = apr,
pages = {1753--1760},
pmid = {22507055},
title = {{Enhancement of neural representation capacity by modular architecture in networks of cortical neurons.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22507055},
volume = {35},
year = {2012}
}
@book{Snyder1991,
author = {Snyder, Donald L and Miller, Michael I},
booktitle = {Springer Texts in Electrical Engineering},
publisher = {Springer-Verlag},
title = {{Random Point Processes in Time and Space}},
year = {1991}
}
@article{Ruttor2009,
author = {Ruttor, Andreas and Opper, Manfred},
file = {:Users/alex/Documents/Mendeley Desktop/Ruttor, Opper - 2009 - Efficient Statistical Inference for Stochastic Reaction Processes.pdf:pdf},
journal = {Physical Review Letters},
number = {x},
title = {{Efficient Statistical Inference for Stochastic Reaction Processes}},
year = {2009}
}
@book{Gardiner2004,
author = {Gardiner, Crispin W},
booktitle = {Springer series in synergetics},
isbn = {3540208828},
pages = {415},
publisher = {Springer},
series = {Series in synergetics},
title = {{Handbook of Stochastic Methods: for Physics, Chemistry and the Natural Sciences}},
url = {http://www.amazon.com/Handbook-Stochastic-Methods-Chemistry-Synergetics/dp/3540208828},
volume = {Vol. 13},
year = {2004}
}
@article{Ma2006,
abstract = {Recent psychophysical experiments indicate that humans perform near-optimal Bayesian inference in a wide variety of tasks, ranging from cue integration to decision making to motor control. This implies that neurons both represent probability distributions and combine those distributions according to a close approximation to Bayes' rule. At first sight, it would seem that the high variability in the responses of cortical neurons would make it difficult to implement such optimal statistical inference in cortical circuits. We argue that, in fact, this variability implies that populations of neurons automatically represent probability distributions over the stimulus, a type of code we call probabilistic population codes. Moreover, we demonstrate that the Poisson-like variability observed in cortex reduces a broad class of Bayesian inference to simple linear combinations of populations of neural activity. These results hold for arbitrary probability distributions over the stimulus, for tuning curves of arbitrary shape and for realistic neuronal variability.},
author = {Ma, Wei Ji and Beck, Jeffrey M and Latham, Peter E and Pouget, Alexandre},
doi = {10.1038/nn1790},
file = {:Users/alex/Documents/Mendeley Desktop/Ma et al. - 2006 - Bayesian inference with probabilistic population codes.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Algorithms,Bayes Theorem,Cerebral Cortex,Cerebral Cortex: physiology,Humans,Models, Neurological,Models, Statistical,Nerve Net,Nerve Net: cytology,Nerve Net: physiology,Normal Distribution,Poisson Distribution},
month = nov,
number = {11},
pages = {1432--8},
pmid = {17057707},
title = {{Bayesian inference with probabilistic population codes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17057707},
volume = {9},
year = {2006}
}
@article{Rabinowitz2011a,
abstract = {The auditory system must represent sounds with a wide range of statistical properties. One important property is the spectrotemporal contrast in the acoustic environment: the variation in sound pressure in each frequency band, relative to the mean pressure. We show that neurons in ferret auditory cortex rescale their gain to partially compensate for the spectrotemporal contrast of recent stimulation. When contrast is low, neurons increase their gain, becoming more sensitive to small changes in the stimulus, although the effectiveness of contrast gain control is reduced at low mean levels. Gain is primarily determined by contrast near each neuron's preferred frequency, but there is also a contribution from contrast in more distant frequency bands. Neural responses are modulated by contrast over timescales of ∼100 ms. By using contrast gain control to expand or compress the representation of its inputs, the auditory system may be seeking an efficient coding of natural sounds.},
author = {Rabinowitz, Neil C and Willmore, Ben D B and Schnupp, Jan W H and King, Andrew J},
doi = {10.1016/j.neuron.2011.04.030},
file = {:Users/alex/Documents/Mendeley Desktop/Rabinowitz et al. - 2011 - Contrast gain control in auditory cortex.pdf:pdf},
issn = {1097-4199},
journal = {Neuron},
keywords = {Acoustic Stimulation,Adaptation, Physiological,Animals,Auditory Cortex,Auditory Cortex: cytology,Auditory Cortex: physiology,Auditory Threshold,Auditory Threshold: physiology,Discrimination (Psychology),Discrimination (Psychology): physiology,Electrophysiology,Female,Ferrets,Male,Models, Neurological,Neurons,Neurons: physiology,Pitch Perception,Pitch Perception: physiology,Sound Spectrography},
month = jun,
number = {6},
pages = {1178--91},
pmid = {21689603},
publisher = {Elsevier Inc.},
title = {{Contrast gain control in auditory cortex.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3133688\&tool=pmcentrez\&rendertype=abstract},
volume = {70},
year = {2011}
}
@article{Lewicki2002,
abstract = {The auditory system encodes sound by decomposing the amplitude signal arriving at the ear into multiple frequency bands whose center frequencies and bandwidths are approximately exponential functions of the distance from the stapes. This organization is thought to result from the adaptation of cochlear mechanisms to the animal's auditory environment. Here we report that several basic auditory nerve fiber tuning properties can be accounted for by adapting a population of filter shapes to encode natural sounds efficiently. The form of the code depends on sound class, resembling a Fourier transformation when optimized for animal vocalizations and a wavelet transformation when optimized for non-biological environmental sounds. Only for the combined set does the optimal code follow scaling characteristics of physiological data. These results suggest that auditory nerve fibers encode a broad set of natural sounds in a manner consistent with information theoretic principles.},
author = {Lewicki, Michael S},
doi = {10.1038/nn831},
file = {:Users/alex/Documents/Mendeley Desktop/Lewicki - 2002 - Efficient coding of natural sounds.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Animals,Auditory Pathways,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: physiology,Cochlea,Cochlea: physiology,Cochlear Nerve,Cochlear Nerve: physiology,Fourier Analysis,Mathematics,Models, Neurological,Regression Analysis,Sound,Time Factors,Vocalization, Animal},
month = apr,
number = {4},
pages = {356--63},
pmid = {11896400},
title = {{Efficient coding of natural sounds.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11896400},
volume = {5},
year = {2002}
}
@inproceedings{Susemihl2011a,
author = {Susemihl, Alex and Meir, Ron and Opper, Manfred},
booktitle = {Advances in Neural Information Processing Systems},
editor = {Shawe-Taylor, J. and Zemel, R. S. and Bartlett, P. and Pereira, F.C.N. and Weinberger, K.Q.},
file = {:Users/alex/Documents/Mendeley Desktop/Susemihl, Meir, Opper - 2011 - Analytical Results for the Error in Filtering of Gaussian Processes.pdf:pdf},
pages = {2303--2311},
title = {{Analytical Results for the Error in Filtering of Gaussian Processes}},
url = {http://books.nips.cc/papers/files/nips24/NIPS2011\_1241.pdf},
year = {2011}
}
@inproceedings{Hausler2012,
address = {M\"{u}nchen},
author = {Hausler, Chris and Susemihl, Alex},
booktitle = {Bernstein Conference 2012},
keywords = {boltzmann machine,deep belief,natural image},
publisher = {Frontiers},
title = {{Encoding and Recall of Natural Image Sequences with Conditionally Restricted Boltzmann Machines}},
url = {http://www.frontiersin.org/10.3389/conf.fncom.2012.55.00143/event\_abstract},
year = {2012}
}
@article{Yaeli2010,
abstract = {Biological systems display impressive capabilities in effectively responding to environmental signals in real time. There is increasing evidence that organisms may indeed be employing near optimal Bayesian calculations in their decision-making. An intriguing question relates to the properties of optimal encoding methods, namely determining the properties of neural populations in sensory layers that optimize performance, subject to physiological constraints. Within an ecological theory of neural encoding/decoding, we show that optimal Bayesian performance requires neural adaptation which reflects environmental changes. Specifically, we predict that neuronal tuning functions possess an optimal width, which increases with prior uncertainty and environmental noise, and decreases with the decoding time window. Furthermore, even for static stimuli, we demonstrate that dynamic sensory tuning functions, acting at relatively short time scales, lead to improved performance. Interestingly, the narrowing of tuning functions as a function of time was recently observed in several biological systems. Such results set the stage for a functional theory which may explain the high reliability of sensory systems, and the utility of neuronal adaptation occurring at multiple time scales.},
author = {Yaeli, Steve and Meir, Ron},
doi = {10.3389/fncom.2010.00130},
file = {:Users/alex/Documents/Mendeley Desktop//Yaeli, Meir - 2010 - Error-based analysis of optimal tuning functions explains phenomena observed in sensory neurons.pdf:pdf},
institution = {Department of Electrical Engineering Technion, Haifa, Israel.},
journal = {Frontiers in computational neuroscience},
keywords = {bayesian decoding,fisher information,neural encoding,optimal width,population coding,tuning functions},
number = {October},
pages = {16},
publisher = {Frontiers Research Foundation},
title = {{Error-based analysis of optimal tuning functions explains phenomena observed in sensory neurons}},
url = {http://eprints.pascal-network.org/archive/00005927/ http://www.frontiersin.org/Computational\_Neuroscience/10.3389/fncom.2010.00130/abstract},
volume = {4},
year = {2010}
}
@article{Dean2005,
abstract = {Mammals can hear sounds extending over a vast range of sound levels with remarkable accuracy. How auditory neurons code sound level over such a range is unclear; firing rates of individual neurons increase with sound level over only a very limited portion of the full range of hearing. We show that neurons in the auditory midbrain of the guinea pig adjust their responses to the mean, variance and more complex statistics of sound level distributions. We demonstrate that these adjustments improve the accuracy of the neural population code close to the region of most commonly occurring sound levels. This extends the range of sound levels that can be accurately encoded, fine-tuning hearing to the local acoustic environment.},
author = {Dean, Isabel and Harper, Nicol S and McAlpine, David},
doi = {10.1038/nn1541},
file = {:Users/alex/Documents/Mendeley Desktop/Dean, Harper, McAlpine - 2005 - Neural population coding of sound level adapts to stimulus statistics.pdf:pdf},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Acoustic Stimulation,Action Potentials,Action Potentials: physiology,Animals,Auditory Pathways,Auditory Pathways: physiology,Auditory Perception,Auditory Perception: physiology,Auditory Threshold,Auditory Threshold: physiology,Guinea Pigs,Inferior Colliculi,Inferior Colliculi: physiology,Loudness Perception,Loudness Perception: physiology,Neurons,Neurons: physiology,Pitch Perception,Pitch Perception: physiology,Reaction Time,Reaction Time: physiology,Sound Localization,Sound Localization: physiology,Synaptic Transmission,Synaptic Transmission: physiology,Time Factors},
month = dec,
number = {12},
pages = {1684--9},
pmid = {16286934},
title = {{Neural population coding of sound level adapts to stimulus statistics.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16286934},
volume = {8},
year = {2005}
}
@article{Riedel1991,
author = {Riedel, K.S.},
file = {:Users/alex/Documents/Mendeley Desktop/Riedel - 1991 - A Sherman-Morrison-Woodbury identity for rank augmenting matrices with application to centering.pdf:pdf},
journal = {SIAM J. Mat. Anal},
keywords = {1,33a65,35k05,62g20,65p05,65r10,ams,generalized inverses,identity,linear algebra,mos,schur matrices,subject classifications,the wellknown sherman-morrison-woodbury matrix},
number = {1},
pages = {80--95},
title = {{A Sherman-Morrison-Woodbury identity for rank augmenting matrices with application to centering}},
url = {http://www.math.nyu.edu/~riedel/ranksiam.pdf},
volume = {12},
year = {1991}
}
@article{Benucci2009,
abstract = {Neuronal populations in sensory cortex represent time-changing sensory input through a spatiotemporal code. What are the rules that govern this code? We measured membrane potentials and spikes from neuronal populations in cat visual cortex (V1) using voltage-sensitive dyes and electrode arrays. We first characterized the population response to a single orientation. As response amplitude grew, the population tuning width remained constant for membrane potential responses and became progressively sharper for spike responses. We then asked how these single-orientation responses combine to code for successive orientations. We found that they combined through simple linear summation. Linearity, however, was violated after stimulus offset, when responses exhibited an unexplained persistence. As a result of linearity, the interactions between responses to successive stimuli were minimal. Our results indicate that higher cortical areas may reconstruct the stimulus sequence from V1 population responses through a simple instantaneous decoder. Therefore, spatial and temporal codes in area V1 operate largely independently.},
author = {Benucci, Andrea and Ringach, Dario L and Carandini, Matteo},
doi = {10.1038/nn.2398},
file = {:Users/alex/Documents/Mendeley Desktop/Benucci, Ringach, Carandini - 2009 - Coding of stimulus sequences by population responses in visual cortex.pdf:pdf},
issn = {1546-1726},
journal = {Nature neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Animals,Brain Mapping,Cats,Electrodes,Fluorescent Dyes,Fluorescent Dyes: metabolism,Membrane Potentials,Membrane Potentials: physiology,Models, Neurological,Neurons,Neurons: physiology,Orientation,Orientation: physiology,Photic Stimulation,Photic Stimulation: methods,Predictive Value of Tests,Reaction Time,Reaction Time: physiology,Time Factors,Visual Cortex,Visual Cortex: cytology},
month = oct,
number = {10},
pages = {1317--24},
pmid = {19749748},
publisher = {Nature Publishing Group},
title = {{Coding of stimulus sequences by population responses in visual cortex.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2847499\&tool=pmcentrez\&rendertype=abstract},
volume = {12},
year = {2009}
}
@book{Anderson1979,
address = {Englewood Cliffs, NJ},
author = {Anderson, Brian D O and Moore, John B},
file = {:Users/alex/Documents/Mendeley Desktop/Anderson, Moore - 1979 - Optimal filtering.PDF:PDF},
publisher = {Prentice-hall},
title = {{Optimal filtering}},
volume = {11},
year = {1979}
}
@article{Sharpee2011,
abstract = {Sensory neurons exhibit two universal properties: sensitivity to multiple stimulus dimensions and adaptation to stimulus statistics. How adaptation affects encoding along primary dimensions is well characterized for most sensory pathways, but if and how it affects secondary dimensions is less clear. We studied these effects for neurons in the avian equivalent of primary auditory cortex, responding to temporally-modulated sounds. We showed that the firing rate of single neurons in field L was affected by at least two components of the time-varying sound log-amplitude. When overall sound amplitude was low, neural responses were based on nonlinear combinations of the mean log-amplitude and its rate of change (first time differential). At high mean sound amplitude, the two relevant stimulus features became the first and second time-derivatives of the sound log-amplitude. Thus, a strikingly systematic relationship between dimensions was conserved across changes in stimulus intensity, whereby one of the relevant dimensions approximated the time differential of the other dimension. In contrast to stimulus mean, increases in stimulus variance did not change relevant dimensions, but selectively increased the contribution of the second dimension to neural firing, illustrating a new adaptive behavior enabled by multi-dimensional encoding. Finally, we demonstrated theoretically that inclusion of time differentials as additional stimulus features, as seen so prominently in the single neuron responses studied here, is a useful strategy for encoding naturalistic stimuli, because it can lower the necessary sampling rate while maintaining the robustness of stimulus reconstruction to correlated noise.},
author = {Sharpee, Tatyana O and Nagel, Katherine I and Doupe, Allison J},
doi = {10.1152/jn.00905.2010},
file = {:Users/alex/Documents/Mendeley Desktop/Sharpee, Nagel, Doupe - 2011 - Two-dimensional adaptation in the auditory forebrain.pdf:pdf},
issn = {1522-1598},
journal = {Journal of neurophysiology},
keywords = {Acoustic Stimulation,Acoustics,Action Potentials,Adaptation,Animals,Auditory,Auditory Cortex,Auditory Cortex: cytology,Auditory Cortex: physiology,Auditory: physiology,Brain Mapping,Evoked Potentials,Finches,Finches: physiology,Models,Neurological,Neurons,Neurons: physiology,Oscillometry,Physiological,Physiological: physiology},
month = jul,
number = {4},
pages = {1841--1861},
pmid = {21753019},
title = {{Two-dimensional adaptation in the auditory forebrain.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21753019},
volume = {106},
year = {2011}
}
@article{Bobrowski2009,
abstract = {A key requirement facing organisms acting in uncertain dynamic environments is the real-time estimation and prediction of environmental states, based on which effective actions can be selected. While it is becoming evident that organisms employ exact or approximate Bayesian statistical calculations for these purposes, it is far less clear how these putative computations are implemented by neural networks in a strictly dynamic setting. In this work, we make use of rigorous mathematical results from the theory of continuous time point process filtering and show how optimal real-time state estimation and prediction may be implemented in a general setting using simple recurrent neural networks. The framework is applicable to many situations of common interest, including noisy observations, non-Poisson spike trains (incorporating adaptation), multisensory integration, and state prediction. The optimal network properties are shown to relate to the statistical structure of the environment, and the benefits of adaptation are studied and explicitly demonstrated. Finally, we recover several existing results as appropriate limits of our general setting.},
annote = {        From Duplicate 1 (                           Bayesian Filtering in Spiking Neural Networks : Noise , Adaptation , and Multisensory Integration                         - Bobrowski, Omer; Meir, Ron; Eldar, Yonina C )
                
        
        
      },
author = {Bobrowski, Omer and Meir, Ron and Eldar, Yonina C},
doi = {10.1162/neco.2008.01-08-692},
file = {:Users/alex/Documents/Mendeley Desktop/Bobrowski, Meir, Eldar - 2009 - Bayesian filtering in spiking neural networks noise, adaptation, and multisensory integration.pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Action Potentials,Action Potentials: physiology,Adaptation,Animals,Bayes Theorem,Computer Simulation,Markov Chains,Models,Neural Networks (Computer),Neural Pathways,Neural Pathways: physiology,Neurological,Noise,Physiological,Physiological: physiology,Sensory Receptor Cells,Sensory Receptor Cells: physiology,Statistical},
month = may,
number = {5},
pages = {1277--320},
pmid = {19018706},
title = {{Bayesian filtering in spiking neural networks: noise, adaptation, and multisensory integration.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19018706},
volume = {21},
year = {2009}
}
@article{Lee2008,
author = {Lee, Honglak and Ekanadham, C},
file = {:Users/alex/Documents/Mendeley Desktop/Lee, Ekanadham - 2008 - Sparse deep belief net model for visual area V2.pdf:pdf},
journal = {Advances in neural information},
pages = {1--8},
title = {{Sparse deep belief net model for visual area V2}},
url = {http://books.nips.cc/papers/txt/nips20/NIPS2007\_0934.txt},
year = {2008}
}
@article{Guo2008,
author = {Guo, Dongning and Shamai, S and Verd\'{u}, Sergio},
file = {:Users/alex/Documents/Mendeley Desktop/Guo, Shamai, Verd\'{u} - 2008 - Mutual information and conditional mean estimation in Poisson channels.pdf:pdf},
journal = {IEEE Transactions on Information Theory},
number = {5},
pages = {1837--1849},
title = {{Mutual information and conditional mean estimation in Poisson channels}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4494688},
volume = {54},
year = {2008}
}
@article{Knill2004,
abstract = {To use sensory information efficiently to make judgments and guide action in the world, the brain must represent and use information about uncertainty in its computations for perception and action. Bayesian methods have proven successful in building computational theories for perception and sensorimotor control, and psychophysics is providing a growing body of evidence that human perceptual computations are "Bayes' optimal". This leads to the "Bayesian coding hypothesis": that the brain represents sensory information probabilistically, in the form of probability distributions. Several computational schemes have recently been proposed for how this might be achieved in populations of neurons. Neurophysiological data on the hypothesis, however, is almost non-existent. A major challenge for neuroscientists is to test these ideas experimentally, and so determine whether and how neurons code information about sensory uncertainty.},
author = {Knill, David C and Pouget, Alexandre},
doi = {10.1016/j.tins.2004.10.007},
file = {:Users/alex/Documents/Mendeley Desktop/Knill, Pouget - 2004 - The Bayesian brain the role of uncertainty in neural coding and computation.pdf:pdf},
issn = {0166-2236},
journal = {Trends in neurosciences},
keywords = {Animals,Bayes Theorem,Brain,Brain: physiology,Humans,Models, Biological,Nerve Net,Neurons,Neurons: metabolism,Perception},
month = dec,
number = {12},
pages = {712--9},
pmid = {15541511},
title = {{The Bayesian brain: the role of uncertainty in neural coding and computation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15541511},
volume = {27},
year = {2004}
}
@article{Takahashi1987,
abstract = {This paper investigates the role of the central nucleus of the barn owl's inferior colliculus in determination of the sound-source azimuth. The central nucleus contains many neurons that are sensitive to interaural time difference (ITD), the cue for azimuth in the barn owl. The response of these neurons varies in a cyclic manner with the ITD of a tone or noise burst. Response maxima recur at integer multiples of the period of the stimulating tone, or, if the stimulus is noise, at integer multiples of the period corresponding to the neuron's best frequency. Such neurons can signal, by means of their relative spike rate, the phase difference between the sounds reaching the left and right ears. Since an interaural phase difference corresponds to more than one ITD, these neurons represent ITD ambiguously. We call this phenomenon phase ambiguity. The central nucleus is tonotopically organized and its neurons are narrowly tuned to frequency. Neurons in an array perpendicular to isofrequency laminae form a physiological and anatomical unit; only one ITD, the array-specific ITD, activates all neurons in an array at the same relative level. We, therefore, may say that, in the central nucleus, an ITD is conserved in an array of neurons. Array-specific ITDs are mapped and encompass the entire auditory space of the barn owl. Individual space-specific neurons of the external nucleus, which receive inputs from a wide range of frequency channels (Knudsen and Konishi, 1978), are selective for a unique ITD. Space-specific neurons do not show phase ambiguity when stimulated with noise (Takahashi and Konishi, 1986). Space-specific neurons receive inputs from arrays that are selective for the same ITD. The collective response of the neurons in an array may be the basis for the absence of phase ambiguity in space-specific neurons.},
author = {Takahashi, Terry},
file = {:Users/alex/Documents/Mendeley Desktop/Takahashi - 1987 - Representation of Interaural Time Difference of the Barn Owl ’ s Inferior Colliculus in the Central Nucleus.pdf:pdf},
journal = {Journal of Neuroscience},
number = {10},
pages = {3105--3116},
title = {{Representation of Interaural Time Difference of the Barn Owl ’ s Inferior Colliculus in the Central Nucleus}},
volume = {7},
year = {1987}
}
@article{Rabinowitz2011,
abstract = {The auditory system must represent sounds with a wide range of statistical properties. One important property is the spectrotemporal contrast in the acoustic environment: the variation in sound pressure in each frequency band, relative to the mean pressure. We show that neurons in ferret auditory cortex rescale their gain to partially compensate for the spectrotemporal contrast of recent stimulation. When contrast is low, neurons increase their gain, becoming more sensitive to small changes in the stimulus, although the effectiveness of contrast gain control is reduced at low mean levels. Gain is primarily determined by contrast near each neuron's preferred frequency, but there is also a contribution from contrast in more distant frequency bands. Neural responses are modulated by contrast over timescales of ∼100 ms. By using contrast gain control to expand or compress the representation of its inputs, the auditory system may be seeking an efficient coding of natural sounds.},
author = {Rabinowitz, Neil C and Willmore, Ben D B and Schnupp, Jan W H and King, Andrew J},
doi = {10.1016/j.neuron.2011.04.030},
issn = {1097-4199},
journal = {Neuron},
month = jun,
number = {6},
pages = {1178--91},
pmid = {21689603},
publisher = {Elsevier Inc.},
title = {{Contrast gain control in auditory cortex.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21689603},
volume = {70},
year = {2011}
}
@inproceedings{Karklin2011,
author = {Karklin, Yan and Simoncelli, Eero P},
booktitle = {Advances in Neural Information Processing Systems 24},
editor = {Shawe-Taylor, J. and Zemel, R.S. and P., Bartlett and Pereira, F.C.N. and Weinberger, K.Q.},
file = {:Users/alex/Documents/Mendeley Desktop//Karklin, Simoncelli - 2011 - Efficient Coding of Natural Images with a Population of Noisy Linear-Nonlinear Neurons.pdf:pdf},
pages = {999--1007},
title = {{Efficient Coding of Natural Images with a Population of Noisy Linear-Nonlinear Neurons}},
year = {2011}
}
@article{Ho2012,
author = {Ho, T. and Brown, S. and van Maanen, L. and Forstmann, B. U. and Wagenmakers, E.-J. and Serences, J. T.},
doi = {10.1523/JNEUROSCI.0340-12.2012},
file = {:Users/alex/Documents/Mendeley Desktop/Ho et al. - 2012 - The Optimality of Sensory Processing during the Speed-Accuracy Tradeoff.pdf:pdf},
issn = {0270-6474},
journal = {Journal of Neuroscience},
month = jun,
number = {23},
pages = {7992--8003},
title = {{The Optimality of Sensory Processing during the Speed-Accuracy Tradeoff}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0340-12.2012},
volume = {32},
year = {2012}
}
@article{Ramirez2011a,
abstract = {Birdsong is comprised of rich spectral and temporal organization, which might be used for vocal perception. To quantify how this structure could be used, we have reconstructed birdsong spectrograms by combining the spike trains of zebra finch auditory midbrain neurons with information about the correlations present in song. We calculated maximum a posteriori estimates of song spectrograms using a generalized linear model of neuronal responses and a series of prior distributions, each carrying different amounts of statistical information about zebra finch song. We found that spike trains from a population of mesencephalicus lateral dorsalis (MLd) neurons combined with an uncorrelated Gaussian prior can estimate the amplitude envelope of song spectrograms. The same set of responses can be combined with Gaussian priors that have correlations matched to those found across multiple zebra finch songs to yield song spectrograms similar to those presented to the animal. The fidelity of spectrogram reconstructions from MLd responses relies more heavily on prior knowledge of spectral correlations than temporal correlations. However, the best reconstructions combine MLd responses with both spectral and temporal correlations.},
author = {Ramirez, Alexandro D and Ahmadian, Yashar and Schumacher, Joseph and Schneider, David and Woolley, Sarah M N and Paninski, Liam},
doi = {10.1523/JNEUROSCI.3256-10.2011},
file = {:Users/alex/Documents/Mendeley Desktop/Ramirez et al. - 2011 - Incorporating naturalistic correlation structure improves spectrogram reconstruction from neuronal activity in the songbird auditory midbrain.pdf:pdf},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Acoustic Stimulation,Action Potentials,Action Potentials: physiology,Animals,Electrophysiology,Finches,Mesencephalon,Mesencephalon: physiology,Neurons,Neurons: physiology,Signal Processing, Computer-Assisted,Sound Spectrography,Sound Spectrography: methods,Vocalization, Animal,Vocalization, Animal: physiology},
month = mar,
number = {10},
pages = {3828--42},
pmid = {21389238},
title = {{Incorporating naturalistic correlation structure improves spectrogram reconstruction from neuronal activity in the songbird auditory midbrain.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3273872\&tool=pmcentrez\&rendertype=abstract},
volume = {31},
year = {2011}
}
@article{Brunel1998,
author = {Brunel, Nicolas and Nadal, JP},
file = {:Users/alex/Documents/Mendeley Desktop/Brunel, Nadal - 1998 - Mutual information, Fisher information, and population coding.pdf:pdf},
journal = {Neural Computation},
number = {7},
title = {{Mutual information, Fisher information, and population coding}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/089976698300017115},
volume = {10},
year = {1998}
}
@article{Stanford2010,
abstract = {In perceptual discrimination tasks, a subject's response time is determined by both sensory and motor processes. Measuring the time consumed by the perceptual evaluation step alone is therefore complicated by factors such as motor preparation, task difficulty and speed-accuracy tradeoffs. Here we present a task design that minimizes these confounding factors and allows us to track a subject's perceptual performance with unprecedented temporal resolution. We find that monkeys can make accurate color discriminations in less than 30 ms. Furthermore, our simple task design provides a tool for elucidating how neuronal activity relates to sensory as opposed to motor processing, as demonstrated with neural data from cortical oculomotor neurons. In these cells, perceptual information acts by accelerating and decelerating the ongoing motor plans associated with correct and incorrect choices, as predicted by a race-to-threshold model, and the time course of these neural events parallels the time course of the subject's choice accuracy.},
author = {Stanford, Terrence R and Shankar, Swetha and Massoglia, Dino P and Costello, M Gabriela and Salinas, Emilio},
doi = {10.1038/nn.2485},
file = {:Users/alex/Documents/Mendeley Desktop/Stanford et al. - 2010 - Perceptual decision making in less than 30 milliseconds.pdf:pdf},
issn = {1546-1726},
journal = {Nature neuroscience},
keywords = {Action Potentials,Animals,Color,Decision Making,Decision Making: physiology,Eye Movement Measurements,Haplorhini,Microelectrodes,Models, Neurological,Neurons,Neurons: physiology,Neuropsychological Tests,Photic Stimulation,Psychometrics,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,Reaction Time: physiology,Saccades,Saccades: physiology,Video Recording,Visual Perception,Visual Perception: physiology},
month = mar,
number = {3},
pages = {379--85},
pmid = {20098418},
publisher = {Nature Publishing Group},
title = {{Perceptual decision making in less than 30 milliseconds.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2834559\&tool=pmcentrez\&rendertype=abstract},
volume = {13},
year = {2010}
}
@book{Oksendal2003,
abstract = {This book gives an introduction to the basic theory of stochastic calculus and its applications. Examples are given throughout the text, in order to motivate and illustrate the theory and show its importance for many applications in e.g. economics, biology and physics. The basic idea of the presentation is to start from some basic results (without proofs) of the easier cases and develop the theory from there, and to concentrate on the proofs of the easier case (which nevertheless are often sufficiently general for many purposes) in order to be able to reach quickly the parts of the theory which is most important for the applications. For the 6th edition the author has added further exercises and, for the first time, solutions to many of the exercises are provided.},
author = {\O ksendal, Bernt},
booktitle = {New York},
doi = {10.1109/TAC.2006.882767},
institution = {Financial Access Initiative},
isbn = {3540047581},
issn = {00189286},
number = {March},
pages = {360},
publisher = {Springer},
series = {Universitext},
title = {{Stochastic Differential Equations: An Introduction with Applications}},
url = {http://books.google.com/books?id=kXw9hB4EEpUC\&pgis=1},
volume = {10},
year = {2003}
}
@article{Harper2004,
author = {Harper, Nicol S and McAlpine, David},
doi = {10.1038/nature02697.1.},
file = {:Users/alex/Documents/Mendeley Desktop/Harper, McAlpine - 2004 - Optimal neural population coding of an auditory spatial cue.pdf:pdf},
journal = {Nature},
number = {August},
pages = {682--686},
title = {{Optimal neural population coding of an auditory spatial cue}},
url = {http://www.nature.com/nature/journal/v430/n7000/abs/nature02768.html},
volume = {430},
year = {2004}
}
@article{Eichhorn2009,
abstract = {Orientation selectivity is the most striking feature of simple cell coding in V1 that has been shown to emerge from the reduction of higher-order correlations in natural images in a large variety of statistical image models. The most parsimonious one among these models is linear Independent Component Analysis (ICA), whereas second-order decorrelation transformations such as Principal Component Analysis (PCA) do not yield oriented filters. Because of this finding, it has been suggested that the emergence of orientation selectivity may be explained by higher-order redundancy reduction. To assess the tenability of this hypothesis, it is an important empirical question how much more redundancy can be removed with ICA in comparison to PCA or other second-order decorrelation methods. Although some previous studies have concluded that the amount of higher-order correlation in natural images is generally insignificant, other studies reported an extra gain for ICA of more than 100\%. A consistent conclusion about the role of higher-order correlations in natural images can be reached only by the development of reliable quantitative evaluation methods. Here, we present a very careful and comprehensive analysis using three evaluation criteria related to redundancy reduction: In addition to the multi-information and the average log-loss, we compute complete rate-distortion curves for ICA in comparison with PCA. Without exception, we find that the advantage of the ICA filters is small. At the same time, we show that a simple spherically symmetric distribution with only two parameters can fit the data significantly better than the probabilistic model underlying ICA. This finding suggests that, although the amount of higher-order correlation in natural images can in fact be significant, the feature of orientation selectivity does not yield a large contribution to redundancy reduction within the linear filter bank models of V1 simple cells.},
author = {Eichhorn, Jan and Sinz, Fabian and Bethge, Matthias},
doi = {10.1371/journal.pcbi.1000336},
file = {:Users/alex/Documents/Mendeley Desktop/Eichhorn, Sinz, Bethge - 2009 - Natural image coding in V1 how much use is orientation selectivity.pdf:pdf},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Animals,Biomimetics,Biomimetics: methods,Computer Simulation,Form Perception,Form Perception: physiology,Humans,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Models, Neurological,Models, Statistical,Sensitivity and Specificity,Visual Cortex,Visual Cortex: physiology},
month = apr,
number = {4},
pages = {e1000336},
pmid = {19343216},
title = {{Natural image coding in V1: how much use is orientation selectivity?}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2658886\&tool=pmcentrez\&rendertype=abstract},
volume = {5},
year = {2009}
}
@article{McNaughton1995,
author = {Knierim, James J and Kudrimoti, Hemant S and McNaughton, Bruce L},
file = {:Users/alex/Documents/Mendeley Desktop/Knierim, Kudrimoti, McNaughton - 1995 - Place Cells , Head Direction Stability Cells , and the Learning of Landmark Stability.pdf:pdf},
journal = {The Journal of neuroscience},
keywords = {head direction,place cells},
number = {March},
pages = {1648--1659},
title = {{Place Cells , Head Direction Stability Cells , and the Learning of Landmark Stability}},
volume = {15},
year = {1995}
}
@article{Pillow2008,
abstract = {Statistical dependencies in the responses of sensory neurons govern both the amount of stimulus information conveyed and the means by which downstream neurons can extract it. Although a variety of measurements indicate the existence of such dependencies, their origin and importance for neural coding are poorly understood. Here we analyse the functional significance of correlated firing in a complete population of macaque parasol retinal ganglion cells using a model of multi-neuron spike responses. The model, with parameters fit directly to physiological data, simultaneously captures both the stimulus dependence and detailed spatio-temporal correlations in population responses, and provides two insights into the structure of the neural code. First, neural encoding at the population level is less noisy than one would expect from the variability of individual neurons: spike times are more precise, and can be predicted more accurately when the spiking of neighbouring neurons is taken into account. Second, correlations provide additional sensory information: optimal, model-based decoding that exploits the response correlation structure extracts 20\% more information about the visual scene than decoding under the assumption of independence, and preserves 40\% more visual information than optimal linear decoding. This model-based approach reveals the role of correlated activity in the retinal coding of visual stimuli, and provides a general framework for understanding the importance of correlated activity in populations of neurons.},
author = {Pillow, Jonathan W and Shlens, Jonathon and Paninski, Liam and Sher, Alexander and Litke, Alan M and Chichilnisky, E J and Simoncelli, Eero P},
doi = {10.1038/nature07140},
file = {:Users/alex/Documents/Mendeley Desktop/Pillow et al. - 2008 - Spatio-temporal correlations and visual signalling in a complete neuronal population.pdf:pdf},
issn = {1476-4687},
journal = {Nature},
keywords = {Action Potentials,Animals,Macaca mulatta,Macaca mulatta: physiology,Models, Neurological,Photic Stimulation,Retinal Ganglion Cells,Retinal Ganglion Cells: physiology,Time Factors,Vision, Ocular,Vision, Ocular: physiology},
month = aug,
number = {7207},
pages = {995--9},
pmid = {18650810},
title = {{Spatio-temporal correlations and visual signalling in a complete neuronal population.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2684455\&tool=pmcentrez\&rendertype=abstract},
volume = {454},
year = {2008}
}
@article{Bethge2003,
author = {Bethge, M and Rotermund, D and Pawelzik, K},
file = {:Users/alex/Documents/Mendeley Desktop/Bethge, Rotermund, Pawelzik - 2003 - Optimal neural rate coding leads to bimodal firing.pdf:pdf},
journal = {Network: Computation in neural systems},
pages = {303--319},
title = {{Optimal neural rate coding leads to bimodal firing}},
volume = {14},
year = {2003}
}
@article{Bar-Shalom1974,
author = {Bar-Shalom, Yaakov and Tse, Edison},
file = {:Users/alex/Documents/Mendeley Desktop/Bar-Shalom, Tse - 1974 - Dual Effect, Certainty Equivalence, and Separation in Stochastic Control.pdf:pdf},
journal = {IEEE Transactions on Automatic Control},
number = {5},
title = {{Dual Effect, Certainty Equivalence, and Separation in Stochastic Control}},
year = {1974}
}
@article{Macke2009,
abstract = {Spike trains recorded from populations of neurons can exhibit substantial pairwise correlations between neurons and rich temporal structure. Thus, for the realistic simulation and analysis of neural systems, it is essential to have efficient methods for generating artificial spike trains with specified correlation structure. Here we show how correlated binary spike trains can be simulated by means of a latent multivariate gaussian model. Sampling from the model is computationally very efficient and, in particular, feasible even for large populations of neurons. The entropy of the model is close to the theoretical maximum for a wide range of parameters. In addition, this framework naturally extends to correlations over time and offers an elegant way to model correlated neural spike counts with arbitrary marginal distributions.},
author = {Macke, Jakob H and Berens, Philipp and Ecker, Alexander S and Tolias, Andreas S and Bethge, Matthias},
institution = {Max Planck Institute for Biological Cybernetics, 72076 T\"{u}bingen, Germany. jakob@tuebingen.mpg.de},
journal = {Neural Computation},
number = {2},
pages = {397--423},
pmid = {19196233},
publisher = {MIT Press},
title = {{Generating spike trains with specified correlation coefficients.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19196233},
volume = {21},
year = {2009}
}
@article{Posner1969a,
author = {Posner, EC and Rodemich, ER and Jr, H Rumsey},
file = {:Users/alex/Documents/Mendeley Desktop/Posner, Rodemich, Jr - 1969 - Epsilon entropy of Gaussian processes.pdf:pdf},
journal = {The Annals of Mathematical \ldots},
number = {4},
pages = {1272--1296},
title = {{Epsilon entropy of Gaussian processes}},
url = {http://www.jstor.org/stable/10.2307/2239594},
volume = {40},
year = {1969}
}
@article{Pitkow2012a,
author = {Pitkow, Xaq and Meister, Markus},
doi = {10.1038/nn.3064},
file = {:Users/alex/Documents/Mendeley Desktop/Pitkow, Meister - 2012 - Decorrelation and efficient coding by retinal ganglion cells.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
month = mar,
number = {4},
pages = {628--635},
publisher = {Nature Publishing Group},
title = {{Decorrelation and efficient coding by retinal ganglion cells}},
url = {http://www.nature.com/doifinder/10.1038/nn.3064},
volume = {15},
year = {2012}
}
@article{Friston2012,
abstract = {This paper describes a variational free-energy formulation of (partially observable) Markov decision problems in decision making under uncertainty. We show that optimal control can be cast as active inference. In active inference, both action and posterior beliefs about hidden states minimise a free energy bound on the negative log-likelihood of observed states, under a generative model. In this setting, reward or cost functions are absorbed into prior beliefs about state transitions and terminal states. Effectively, this converts optimal control into a pure inference problem, enabling the application of standard Bayesian filtering techniques. We then consider optimal trajectories that rest on posterior beliefs about hidden states in the future. Crucially, this entails modelling control as a hidden state that endows the generative model with a representation of agency. This leads to a distinction between models with and without inference on hidden control states; namely, agency-free and agency-based models, respectively.},
author = {Friston, Karl and Samothrakis, Spyridon and Montague, Read},
doi = {10.1007/s00422-012-0512-8},
issn = {1432-0770},
journal = {Biological cybernetics},
keywords = {action,agency,bayesian,free energy,inference,optimal control,partially observable markov decision,processes},
month = aug,
pmid = {22864468},
title = {{Active inference and agency: optimal control without cost functions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22864468},
year = {2012}
}
@article{attneave1954some,
author = {Attneave, F},
journal = {Psychological review},
number = {3},
pages = {183},
publisher = {American Psychological Association},
title = {{Some informational aspects of visual perception.}},
volume = {61},
year = {1954}
}
